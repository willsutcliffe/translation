{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dddc3574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "file = \"en_fr\"\n",
    "df1 = pd.read_csv(\"/home/sutclw/Work/Preparation/Projects/translation/Notebooks/en_ru.csv\")\n",
    "df2 = pd.read_csv(\"/home/sutclw/Work/Preparation/Projects/translation/Notebooks/en_ru_2.csv\")\n",
    "\n",
    "#df = df1.append(df2)\n",
    "df1.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6586a0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ru</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>–î–∞–≤–∞–π—Ç–µ —á—Ç–æ-–Ω–∏–±—É–¥—å –ø–æ–ø—Ä–æ–±—É–µ–º!</td>\n",
       "      <td>Let's try something.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>–ú–Ω–µ –ø–æ—Ä–∞ –∏–¥—Ç–∏ —Å–ø–∞—Ç—å.</td>\n",
       "      <td>I have to go to sleep.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>–ß—Ç–æ —Ç—ã –¥–µ–ª–∞–µ—à—å?</td>\n",
       "      <td>What are you doing?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>–ß—Ç–æ —Ç—ã –¥–µ–ª–∞–µ—à—å?</td>\n",
       "      <td>What do you make?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>–ß—Ç–æ —Ç—ã –¥–µ–ª–∞–µ—à—å?</td>\n",
       "      <td>What're you doing?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656928</th>\n",
       "      <td>656929</td>\n",
       "      <td>–õ–∏—Ñ—Ç –≤—Å—ë –µ—â—ë –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç?</td>\n",
       "      <td>Is the elevator still out of order?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656929</th>\n",
       "      <td>656930</td>\n",
       "      <td>–Ø —Å–∫–∞–∑–∞–ª —Ç–µ–±–µ, —á—Ç–æ–±—ã —Ç—ã –æ—Å—Ç–∞–≤–∞–ª—Å—è –∑–¥–µ—Å—å.</td>\n",
       "      <td>I told you to stay here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656930</th>\n",
       "      <td>656931</td>\n",
       "      <td>–Ø —Å–∫–∞–∑–∞–ª —Ç–µ–±–µ, —á—Ç–æ–±—ã —Ç—ã –æ—Å—Ç–∞–≤–∞–ª–∞—Å—å –∑–¥–µ—Å—å.</td>\n",
       "      <td>I told you to stay here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656931</th>\n",
       "      <td>656932</td>\n",
       "      <td>–Ø —Å–∫–∞–∑–∞–ª –≤–∞–º, —á—Ç–æ–±—ã –≤—ã –æ—Å—Ç–∞–≤–∞–ª–∏—Å—å –∑–¥–µ—Å—å.</td>\n",
       "      <td>I told you to stay here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656932</th>\n",
       "      <td>656933</td>\n",
       "      <td>–î–∂–∏–Ω—Å—ã –∫–æ –≤—Å–µ–º—É –ø–æ–¥—Ö–æ–¥—è—Ç.</td>\n",
       "      <td>Jeans go with everything.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>656933 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                         ru  \\\n",
       "0                1              –î–∞–≤–∞–π—Ç–µ —á—Ç–æ-–Ω–∏–±—É–¥—å –ø–æ–ø—Ä–æ–±—É–µ–º!   \n",
       "1                2                       –ú–Ω–µ –ø–æ—Ä–∞ –∏–¥—Ç–∏ —Å–ø–∞—Ç—å.   \n",
       "2                3                            –ß—Ç–æ —Ç—ã –¥–µ–ª–∞–µ—à—å?   \n",
       "3                4                            –ß—Ç–æ —Ç—ã –¥–µ–ª–∞–µ—à—å?   \n",
       "4                5                            –ß—Ç–æ —Ç—ã –¥–µ–ª–∞–µ—à—å?   \n",
       "...            ...                                        ...   \n",
       "656928      656929                  –õ–∏—Ñ—Ç –≤—Å—ë –µ—â—ë –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç?   \n",
       "656929      656930   –Ø —Å–∫–∞–∑–∞–ª —Ç–µ–±–µ, —á—Ç–æ–±—ã —Ç—ã –æ—Å—Ç–∞–≤–∞–ª—Å—è –∑–¥–µ—Å—å.   \n",
       "656930      656931  –Ø —Å–∫–∞–∑–∞–ª —Ç–µ–±–µ, —á—Ç–æ–±—ã —Ç—ã –æ—Å—Ç–∞–≤–∞–ª–∞—Å—å –∑–¥–µ—Å—å.   \n",
       "656931      656932   –Ø —Å–∫–∞–∑–∞–ª –≤–∞–º, —á—Ç–æ–±—ã –≤—ã –æ—Å—Ç–∞–≤–∞–ª–∏—Å—å –∑–¥–µ—Å—å.   \n",
       "656932      656933                  –î–∂–∏–Ω—Å—ã –∫–æ –≤—Å–µ–º—É –ø–æ–¥—Ö–æ–¥—è—Ç.   \n",
       "\n",
       "                                         en  \n",
       "0                      Let's try something.  \n",
       "1                    I have to go to sleep.  \n",
       "2                       What are you doing?  \n",
       "3                         What do you make?  \n",
       "4                        What're you doing?  \n",
       "...                                     ...  \n",
       "656928  Is the elevator still out of order?  \n",
       "656929             I told you to stay here.  \n",
       "656930             I told you to stay here.  \n",
       "656931             I told you to stay here.  \n",
       "656932            Jeans go with everything.  \n",
       "\n",
       "[656933 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c330c467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a161600",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b67ac7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ru-en\")\n",
    "\n",
    "#model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-ru-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c48941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b561f424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4287ce2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-84210adc254c38ba\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/sutclw/.cache/huggingface/datasets/csv/default-84210adc254c38ba/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sutclw/.local/lib/python3.10/site-packages/datasets/download/streaming_download_manager.py:776: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/sutclw/.cache/huggingface/datasets/csv/default-84210adc254c38ba/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Unnamed: 0.1', 'Unnamed: 0', 'ru', 'en'],\n",
      "        num_rows: 656933\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sutclw/anaconda3/envs/torch/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from translation.models.encoder import Encoder\n",
    "from translation.models.decoder import Decoder\n",
    "from translation.models.transformers import Transformer\n",
    "from translation.training.littrainer import  LitTrainer\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "import pytorch_lightning as pl\n",
    "from translation.models.transformers import Transformer\n",
    "from translation.models.encoder import Encoder\n",
    "from translation.models.decoder import Decoder\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "def preprocess_function(batch,lang='en-ru'):\n",
    "    l1 = lang.split('-')[0]\n",
    "    l2 = lang.split('-')[1]\n",
    "    model_inputs = tokenizer(\n",
    "        batch[l1], max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Set up the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(batch[l2], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "# Press the green button in the gutter to run the script.\n",
    "\n",
    "    print('PyCharm')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "raw_dataset = load_dataset('csv',\n",
    "        data_files='test.csv')\n",
    "print(raw_dataset)\n",
    "lang_pair = \"en-ru\"\n",
    "l1 = lang_pair.split('-')[0]\n",
    "l2 = lang_pair.split('-')[1]\n",
    "lang_pair = \"en-ru\"\n",
    "model_checkpoint = f\"Helsinki-NLP/opus-mt-{lang_pair}\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "split = raw_dataset['train'].train_test_split(test_size=0.05, seed=42)\n",
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "\n",
    "tokenized_datasets = split.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=split[\"train\"].column_names,\n",
    ")\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer)\n",
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(0, 5)])\n",
    "batch.keys()\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=64,\n",
    "    collate_fn=data_collator,\n",
    "    num_workers=4, pin_memory=True,\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    tokenized_datasets[\"test\"],\n",
    "    batch_size=64,\n",
    "    collate_fn=data_collator,\n",
    "    num_workers=4, pin_memory=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f4385dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 624086\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 32847\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b94834d",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b819b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using encoder without a target.\n",
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (embedding): Embedding(62519, 128)\n",
       "  (pos_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): DecoderBlock(\n",
       "      (linear1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mhatt1): MultiHeadAttention(\n",
       "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (mhatt2): MultiHeadAttention(\n",
       "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (nn): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): DecoderBlock(\n",
       "      (linear1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mhatt1): MultiHeadAttention(\n",
       "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (mhatt2): MultiHeadAttention(\n",
       "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (nn): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): DecoderBlock(\n",
       "      (linear1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mhatt1): MultiHeadAttention(\n",
       "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (mhatt2): MultiHeadAttention(\n",
       "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (nn): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): DecoderBlock(\n",
       "      (linear1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (mhatt1): MultiHeadAttention(\n",
       "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (mhatt2): MultiHeadAttention(\n",
       "        (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (fc): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (nn): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (linear): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc): Linear(in_features=128, out_features=62519, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(vocab_size=tokenizer.vocab_size + 1,\n",
    "                  max_len=128,\n",
    "                  d_key=16,\n",
    "                  d_model=128,\n",
    "                  n_heads=8,\n",
    "                  n_layers=4,\n",
    "                  dropout_prob=0.1)\n",
    "decoder = Decoder(vocab_size=tokenizer.vocab_size + 1,\n",
    "                  max_len=128,\n",
    "                  d_key=16,\n",
    "                  d_model=128,\n",
    "                  n_heads=8,\n",
    "                  n_layers=4,\n",
    "                  dropout_prob=0.1)\n",
    "transformer = Transformer(encoder, decoder)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5911c917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "======================================================================\n",
       "Layer (type:depth-idx)                        Param #\n",
       "======================================================================\n",
       "Transformer                                   --\n",
       "‚îú‚îÄEncoder: 1-1                                --\n",
       "‚îÇ    ‚îî‚îÄEmbedding: 2-1                         8,002,432\n",
       "‚îÇ    ‚îî‚îÄPositionalEncoding: 2-2                --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 3-1                      --\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-3                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄEncoderBlock: 3-2                 198,272\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄEncoderBlock: 3-3                 198,272\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄEncoderBlock: 3-4                 198,272\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄEncoderBlock: 3-5                 198,272\n",
       "‚îÇ    ‚îî‚îÄLayerNorm: 2-4                         256\n",
       "‚îú‚îÄDecoder: 1-2                                --\n",
       "‚îÇ    ‚îî‚îÄEmbedding: 2-5                         8,002,432\n",
       "‚îÇ    ‚îî‚îÄPositionalEncoding: 2-6                --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDropout: 3-6                      --\n",
       "‚îÇ    ‚îî‚îÄSequential: 2-7                        --\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDecoderBlock: 3-7                 264,576\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDecoderBlock: 3-8                 264,576\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDecoderBlock: 3-9                 264,576\n",
       "‚îÇ    ‚îÇ    ‚îî‚îÄDecoderBlock: 3-10                264,576\n",
       "‚îÇ    ‚îî‚îÄLayerNorm: 2-8                         256\n",
       "‚îÇ    ‚îî‚îÄLinear: 2-9                            8,064,951\n",
       "======================================================================\n",
       "Total params: 25,921,719\n",
       "Trainable params: 25,921,719\n",
       "Non-trainable params: 0\n",
       "======================================================================"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "# summary(model, input_size=(16,512), dtypes=['torch.IntTensor'], device='cpu')\n",
    "summary(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f7d4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1007ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input_sentence):\n",
    "  # get encoder output first\n",
    "    enc_input = tokenizer(input_sentence, return_tensors='pt').to(device)\n",
    "    #print(device)\n",
    "    enc_output = encoder(enc_input['input_ids'], enc_input['attention_mask'])\n",
    "\n",
    "    # setup initial decoder input\n",
    "    dec_input_ids = torch.tensor([[ int(tokenizer.vocab_size)]], device=device)\n",
    "    dec_attn_mask = torch.ones_like(dec_input_ids, device=device)\n",
    "\n",
    "  # now do the decoder loop\n",
    "    for _ in range(32):\n",
    "        dec_output = decoder(\n",
    "            enc_output,\n",
    "            dec_input_ids,\n",
    "            enc_input['attention_mask'],\n",
    "            dec_attn_mask,\n",
    "        )\n",
    "\n",
    "        # choose the best value (or sample)\n",
    "        prediction_id = torch.argmax(dec_output[:, -1, :], axis=-1)\n",
    "\n",
    "        # append to decoder input\n",
    "        dec_input_ids = torch.hstack((dec_input_ids, prediction_id.view(1, 1)))\n",
    "\n",
    "        # recreate mask\n",
    "        dec_attn_mask = torch.ones_like(dec_input_ids)\n",
    "\n",
    "        # exit when reach </s>\n",
    "        if prediction_id == 0:\n",
    "            break\n",
    "  \n",
    "    translation = tokenizer.decode(dec_input_ids[0, 1:])\n",
    "    #print(translation)\n",
    "    return(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ba159fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "optimizer = torch.optim.Adam(transformer.parameters(),lr=1e-5)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b48ce324",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14172/3816762898.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
      "  bleu_metric = load_metric(\"sacrebleu\")\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "bleu_metric = load_metric(\"sacrebleu\")\n",
    "bert_metric = load_metric(\"bertscore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a65b52",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5da2231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa93ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# A function to encapsulate the training loop\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "def train(model, criterion, optimizer, train_loader, valid_loader, epochs):\n",
    "    train_losses = np.zeros(epochs)\n",
    "    test_losses = np.zeros(epochs)\n",
    "\n",
    "    for it in range(epochs):\n",
    "        model.train()\n",
    "        t0 = datetime.now()\n",
    "        train_loss = []\n",
    "        for batch in train_loader:\n",
    "            # move data to GPU (enc_input, enc_mask, translation)\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            enc_input = batch['input_ids']\n",
    "            enc_mask = batch['attention_mask']\n",
    "            targets = batch['labels']\n",
    "\n",
    "            # shift targets forwards to get decoder_input\n",
    "            dec_input = targets.clone().detach()\n",
    "            dec_input = torch.roll(dec_input, shifts=1, dims=1)\n",
    "            dec_input[:, 0] = int(tokenizer.vocab_size)\n",
    "\n",
    "            # also convert all -100 to pad token id\n",
    "            dec_input = dec_input.masked_fill(\n",
    "              dec_input == -100, tokenizer.pad_token_id)\n",
    "\n",
    "            # make decoder input mask\n",
    "            dec_mask = torch.ones_like(dec_input)\n",
    "            dec_mask = dec_mask.masked_fill(dec_input == tokenizer.pad_token_id, 0)\n",
    "\n",
    "            # Forward pass\n",
    "            with torch.amp.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "                outputs = model(enc_input, dec_input, enc_mask, dec_mask)\n",
    "                loss = criterion(outputs.transpose(2, 1), targets)\n",
    "\n",
    "            # Backward and optimize\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            \n",
    "            scaler.update()\n",
    "            #scheduler.step(optimizer)\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        # Get train loss and test loss\n",
    "        train_loss = np.mean(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = []\n",
    "        for batch in valid_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            enc_input = batch['input_ids']\n",
    "            enc_mask = batch['attention_mask']\n",
    "            targets = batch['labels']\n",
    "\n",
    "            # shift targets forwards to get decoder_input\n",
    "            dec_input = targets.clone().detach()\n",
    "            dec_input = torch.roll(dec_input, shifts=1, dims=1)\n",
    "            dec_input[:, 0] = int(tokenizer.vocab_size)\n",
    "\n",
    "            # change -100s to regular padding\n",
    "            dec_input = dec_input.masked_fill(\n",
    "              dec_input == -100, tokenizer.pad_token_id)\n",
    "\n",
    "            # make decoder input mask\n",
    "            dec_mask = torch.ones_like(dec_input)\n",
    "            dec_mask = dec_mask.masked_fill(dec_input == tokenizer.pad_token_id, 0)\n",
    "\n",
    "            outputs = model(enc_input, dec_input, enc_mask, dec_mask)\n",
    "            #with torch.amp.autocast(device_type=‚Äúcuda‚Äù, dtype=torch.float16):\n",
    "            loss = criterion(outputs.transpose(2, 1), targets)\n",
    "            test_loss.append(loss.item())\n",
    "        test_loss = np.mean(test_loss)\n",
    "\n",
    "        # Save losses\n",
    "        train_losses[it] = train_loss\n",
    "        test_losses[it] = test_loss\n",
    "\n",
    "        dt = datetime.now() - t0\n",
    "        translations = []\n",
    "        targets = []\n",
    "        bertscores = []\n",
    "        bleuscores = []\n",
    "        for  i in range(400):\n",
    "            translations.append(translate(split['test'][i][l1])[:-4])\n",
    "            targets.append(split['test'][i][l2])\n",
    "            score =bert_metric.compute(predictions=[translations[i]], references=[targets[i]], lang=\"ru\")['f1']\n",
    "            bertscores.append(score)\n",
    "            score =bleu_metric.compute(predictions=[translations[i]], references=[[targets[i]]])['score']\n",
    "            bleuscores.append(score)\n",
    "        lscheduler.step()\n",
    "        print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
    "          Test Loss: {test_loss:.4f}, Duration: {dt}')\n",
    "        print(f\"Mean BERT {np.mean(bertscores)}, Mean Bleu: {np.mean(bleuscores)}\" )\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3b6540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75140e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, test_losses = train(\n",
    "    transformer, criterion, optimizer, train_loader, valid_loader, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f566a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(transformer.state_dict(), \"en_ru_transformer_16epochs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db3e6942",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = []\n",
    "targets = []\n",
    "bertscores = []\n",
    "bleuscores = []\n",
    "for  i in range(1000):\n",
    "    translations.append(translate(split['test'][i][l1])[:-4])\n",
    "    targets.append(split['test'][i][l2])\n",
    "    score =bert_metric.compute(predictions=[translations[i]], references=[targets[i]], lang=\"ru\")['f1']\n",
    "    bertscores.append(score)\n",
    "    score =bleu_metric.compute(predictions=[translations[i]], references=[[targets[i]]])['score']\n",
    "    bleuscores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f56f25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9134581453204155"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(bertscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82340e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.68201343735392"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(bleuscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6746aaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–¢–æ–º –ø—Ä–µ–∑–∏—Ä–∞–ª –ú—ç—Ä–∏.\n",
      "–¢–æ–º –ø—Ä–µ–∑–∏—Ä–∞–ª –ú—ç—Ä–∏.\n",
      "\n",
      "–û–Ω –æ–±–µ—â–∞–ª, —á—Ç–æ —Å–¥–µ–ª–∞–µ—Ç —ç—Ç–æ.\n",
      "–û–Ω –æ–±–µ—â–∞–ª, —á—Ç–æ —Å–¥–µ–ª–∞–µ—Ç —ç—Ç–æ.\n",
      "\n",
      "–¢—ã –ø–æ—Ö–æ–∂ –Ω–∞ –¥–æ–≤–æ–ª—å–Ω—ã.\n",
      "–¢—ã –≤—ã–≥–ª—è–¥–∏—à—å –¥–æ–≤–æ–ª—å–Ω–æ–π.\n",
      "\n",
      "–ö–∞–∫ –±—ã–ª–∞ —Ç–≤–æ–π —É—Ä–æ–∫?\n",
      "–ö–∞–∫ –ø—Ä–æ—à–ª–æ –∑–∞–Ω—è—Ç–∏–µ?\n",
      "\n",
      "–ö—Ç–æ –≤—ã–∑–≤–∞–ª –ê–Ω–Ω–∞?\n",
      "–ö—Ç–æ –∑–≤–æ–Ω–∏–ª –≠–Ω–Ω?\n",
      "\n",
      "–ó–∞–π–º–∏ –µ–≥–æ –≤ —Å—É—Ö!\n",
      "–ó–∞—Ç–æ—á–∏—Ç—å –µ–≥–æ –≤ —Ç–µ–º–Ω–∏—Ü—É!\n",
      "\n",
      "–ß–µ–≥–æ –µ—â—ë –¢–æ–º —Ö–æ—á–µ—Ç?\n",
      "–ß–µ–≥–æ –µ—â—ë –¢–æ–º —Ö–æ—á–µ—Ç?\n",
      "\n",
      "–¢–æ–º —É—à—ë–ª —Ä–∞–Ω—å—à–µ.\n",
      "–¢–æ–º —É—à—ë–ª —Ä–∞–Ω—å—à–µ.\n",
      "\n",
      "–¢–æ–º —Å–ª–∏—à–∫–æ–º –º–æ–ª–æ–¥, —á—Ç–æ–±—ã –≥–æ–ª–æ—Å–æ–≤–∞—Ç—å.\n",
      "–¢–æ–º—É —Ä–∞–Ω–æ –≥–æ–ª–æ—Å–æ–≤–∞—Ç—å.\n",
      "\n",
      "–ú—ã –Ω–∞–π–¥—ë–º —Ä–µ—à–µ–Ω–∏–µ, —è —É–≤–µ—Ä–µ–Ω.\n",
      "–ú—ã –Ω–∞–π–¥—ë–º —Ä–µ—à–µ–Ω–∏–µ, —è —É–≤–µ—Ä–µ–Ω.\n",
      "\n",
      "–ö–æ–≥–¥–∞ —Ç–≤–æ–π –ø–µ—Ä–≤—ã–π –∫–ª–∞—Å—Å?\n",
      "–ö–æ–≥–¥–∞ —É –≤–∞—Å –ø–µ—Ä–≤—ã–π —É—Ä–æ–∫?\n",
      "\n",
      "–Ø –≤–∏–¥–µ–ª, –∫–∞–∫ –¢–æ–º –∏ –ú—ç—Ä–∏ –¥–µ—Ä–∂–∞–ª–∏—Å—å —Ä—É–∫–∏.\n",
      "–Ø –≤–∏–¥–µ–ª, –∫–∞–∫ –¢–æ–º —Å –ú—ç—Ä–∏ –¥–µ—Ä–∂–∞–ª–∏—Å—å –∑–∞ —Ä—É–∫–∏.\n",
      "\n",
      "–ù–µ –≥–æ–≤–æ—Ä–∏ –º–Ω–µ, —á—Ç–æ —è —É–∂–µ –∑–Ω–∞—é.\n",
      "–ù–µ –≥–æ–≤–æ—Ä–∏—Ç–µ –º–Ω–µ —Ç–æ–≥–æ, —á—Ç–æ —è –∏ —Ç–∞–∫ –∑–Ω–∞—é.\n",
      "\n",
      "–ï—Å–ª–∏ –±—ã –∂–µ–Ω—â–∏–Ω—ã –∑–Ω–∞–ª–∏, —Å–∫–æ–ª—å–∫–æ –±—ã –º—ã –ø–æ –Ω–µ–º—É –º–Ω–æ–≥–æ —Ä–∞–∑ —Å–∫—É—á–∞–ª–∏, –æ–Ω–∏ –±—ã —É—à–ª–∏.\n",
      "–ï—Å–ª–∏ –±—ã –∂–µ–Ω—â–∏–Ω—ã –∑–Ω–∞–ª–∏, –∫–∞–∫ –º—ã –ø–æ –Ω–∏–º —Å–∫—É—á–∞–µ–º, –æ–Ω–∏ –±—ã —Ä–∞–Ω—å—à–µ —É—Ö–æ–¥–∏–ª–∏.\n",
      "\n",
      "–û—Ç–∫—É–¥–∞ —Ç—ã –∑–Ω–∞–µ—à—å, —á—Ç–æ —ç—Ç–æ –Ω–µ–ø—Ä–∞–≤–¥–∞?\n",
      "–û—Ç–∫—É–¥–∞ –≤—ã –∑–Ω–∞–µ—Ç–µ, —á—Ç–æ —ç—Ç–æ –Ω–µ–ø—Ä–∞–≤–¥–∞?\n",
      "\n",
      "–ù–µ –≥–æ–≤–æ—Ä–∏ —Å –∞–≤—Ç–æ–±—É—Å–æ–º, –ø–æ–∫–∞ –æ–Ω –µ–¥–µ—Ç –Ω–∞ –∞–≤—Ç–æ–±—É—Å–µ.\n",
      "–ù–µ —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞–π—Ç–µ —Å –≤–æ–¥–∏—Ç–µ–ª–µ–º –∞–≤—Ç–æ–±—É—Å–∞ –≤–æ –≤—Ä–µ–º—è –¥–≤–∏–∂–µ–Ω–∏—è.\n",
      "\n",
      "–°–ø–æ–∫–æ—è–¥—å –¢–æ–º–∞ —É–¥–∏–≤–∏–ª –º–µ–Ω—è.\n",
      "–ú–æ–ª—á–∞–Ω–∏–µ –¢–æ–º–∞ –º–µ–Ω—è —É–¥–∏–≤–∏–ª–æ.\n",
      "\n",
      "–ì–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –±–ª–∏–∂–∞–π—à–∏–π –∞–≤—Ç–æ–±—É—Å?\n",
      "–ì–¥–µ –±–ª–∏–∂–∞–π—à–∞—è –∞–≤—Ç–æ–±—É—Å–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞?\n",
      "\n",
      "–£ –º–µ–Ω—è –Ω–∏–∫–æ–≥–¥–∞ —Ä–∞–Ω—å—à–µ –Ω–µ –±—ã–ª–æ –±–æ–ª–∏—Ç –±–æ–ª–∏—Ç –±–æ–ª–∏—Ç.\n",
      "–£ –º–µ–Ω—è –µ—â—ë –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –±—ã–ª–æ —Ç–∞–∫–æ–π —Å–∏–ª—å–Ω–æ–π –≥–æ–ª–æ–≤–Ω–æ–π –±–æ–ª–∏.\n",
      "\n",
      "–ú–æ–∂–Ω–æ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤–∞—à–µ–π —Ç—É–∞–ª–µ—Ç–æ–º?\n",
      "–ú–æ–∂–Ω–æ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ç–≤–æ–∏–º —Ç—É–∞–ª–µ—Ç–æ–º?\n",
      "\n",
      "–¢–æ–º —Å–∫–∞–∑–∞–ª, —á—Ç–æ –Ω–∞–¥–µ–µ—Ç—Å—è, —á—Ç–æ –≤—ã —ç—Ç–æ —Å–¥–µ–ª–∞–µ—Ç–µ.\n",
      "–¢–æ–º —Å–∫–∞–∑–∞–ª, —á—Ç–æ –Ω–∞–¥–µ–µ—Ç—Å—è, —á—Ç–æ –≤—ã —ç—Ç–æ —Å–¥–µ–ª–∞–µ—Ç–µ.\n",
      "\n",
      "–¢–æ–º –∏ –ú—ç—Ä–∏ –∏–∑—É—á–∞—é—Ç —Ç–æ –∂–µ –≥—Ä—É–ø–ø–µ.\n",
      "–¢–æ–º –∏ –ú—ç—Ä–∏ –≤ –æ–¥–Ω–æ–π —É—á–µ–±–Ω–æ–π –≥—Ä—É–ø–ø–µ.\n",
      "\n",
      "–Ø —Å–µ–≥–æ–¥–Ω—è –æ—á–µ–Ω—å —É—Å—Ç–∞–ª.\n",
      "–°–µ–≥–æ–¥–Ω—è —è –æ—á–µ–Ω—å —É—Å—Ç–∞–ª–∞.\n",
      "\n",
      "–Ø —Ö–æ—á—É –ø–æ–Ω—è—Ç—å –¢–æ–º–∞.\n",
      "–Ø —Ö–æ—á—É –ø–æ–Ω—è—Ç—å –¢–æ–º–∞.\n",
      "\n",
      "–ú–æ—è –Ω–æ–≥–∞ –æ–ø—è—Ç—å —Å–ø–∏—Ç!\n",
      "–ù–æ–≥–∞ –æ–ø—è—Ç—å –∑–∞—Ç–µ–∫–ª–∞.\n",
      "\n",
      "–≠—Ç–æ —è –ø—Ä–µ–ø–æ–¥–∞–≤–∞–ª –¢–æ–º–∞ —Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π.\n",
      "–≠—Ç–æ —è —É—á—É –¢–æ–º–∞ —Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–æ–º—É.\n",
      "\n",
      "–ö–∞–∫–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç—ã?\n",
      "–ö–∞–∫–∏–µ –µ—Å—Ç—å –≤–∞—Ä–∏–∞–Ω—Ç—ã?\n",
      "\n",
      "–¢–æ–º –ø–æ—Å–º–æ—Ç—Ä–µ–ª.\n",
      "–¢–æ–º –ø–æ—Å–º–æ—Ç—Ä–µ–ª –Ω–∞–≤–µ—Ä—Ö.\n",
      "\n",
      "–û–Ω –Ω–µ –≤—ã–≥–ª—è–¥–∏—Ç –æ—á–µ–Ω—å —Å—á–∞—Å—Ç–ª–∏–≤—ã–º.\n",
      "–û–Ω –Ω–µ –≤—ã–≥–ª—è–¥–∏—Ç –æ—Å–æ–±–µ–Ω–Ω–æ —Å—á–∞—Å—Ç–ª–∏–≤—ã–º.\n",
      "\n",
      "–ü–æ–ª–æ–≤–æ—Ä–∞ —è–±–ª–æ–∫–æ –±—ã–ª –≥–∞–ª—Å—Ç–æ—Ç.\n",
      "–ü–æ–ª–æ–≤–∏–Ω–∞ —è–±–ª–æ–∫–∞ –±—ã–ª–∞ –≥–Ω–∏–ª–æ–π.\n",
      "\n",
      "–¢—ã —Å—Ç—Ä–∞–Ω–Ω—ã–π —á–µ–ª–æ–≤–µ–∫.\n",
      "–¢—ã —Å—Ç—Ä–∞–Ω–Ω—ã–π —á–µ–ª–æ–≤–µ–∫.\n",
      "\n",
      "–¢–µ–±–µ, –Ω–∞–≤–µ—Ä–Ω–æ–µ, –Ω–µ —Å—Ç–æ–∏—Ç –≥–æ–≤–æ—Ä–∏—Ç—å –¢–æ–º—É, —á—Ç–æ–±—ã –æ–Ω —ç—Ç–æ —Å–¥–µ–ª–∞–ª.\n",
      "–¢–µ–±–µ, –Ω–∞–≤–µ—Ä–Ω–æ–µ, –Ω–µ —Å—Ç–æ–∏—Ç –≥–æ–≤–æ—Ä–∏—Ç—å –¢–æ–º—É, —á—Ç–æ–±—ã –æ–Ω —ç—Ç–æ —Å–¥–µ–ª–∞–ª.\n",
      "\n",
      "–Ø –Ω–µ –∑–Ω–∞–ª, —á—Ç–æ —Ç—ã —É–º–µ–µ—à—å –∏–≥—Ä–∞—Ç—å –Ω–∞ –∫–∞—Ö–±–æ–Ω–µ.\n",
      "–Ø –Ω–µ –∑–Ω–∞–ª, —á—Ç–æ —Ç—ã —É–º–µ–µ—à—å –∏–≥—Ä–∞—Ç—å –Ω–∞ —Ç—Ä–æ–º–±–æ–Ω–µ.\n",
      "\n",
      "–ù–∞ –º–µ–Ω—è –∏–≥—Ä–∞–ª–∏ –º–∞–ª–æ –∂–∏–≤–æ—Ç–Ω—ã—Ö.\n",
      "–ü–∞—Ä–∞ –∑–≤–µ—Ä–µ–π –∏–≥—Ä–∞–ª–∞ –Ω–∞ –ª—É–≥—É.\n",
      "\n",
      "–†–µ–º–æ–±–∏–ª—å –Ω–∞–∑—ã–≤–∞—é—Ç —ç—Ç—É —Ä–µ–∫—É \"—Å–∏–¥–∫—É –∏ —Å—Ç—Ä–∞—Ö.\n",
      "–ú–µ—Å—Ç–Ω—ã–µ –∂–∏—Ç–µ–ª–∏ –Ω–∞–∑—ã–≤–∞—é—Ç —ç—Ç—É —Ä–µ–∫—É \"–ª—é–¥–æ–µ–¥–æ–º\" –∏ –±–æ—è—Ç—Å—è –µ—ë.\n",
      "\n",
      "–í —ç—Ç–æ–º —Å–∞–π—Ç–µ –º–Ω–æ–≥–æ –∏–¥–µ–π.\n",
      "–ù–∞ —ç—Ç–æ–º —Å–∞–π—Ç–µ –º–Ω–æ–≥–æ –ø–æ–ª–µ–∑–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π.\n",
      "\n",
      "–Ø —Ä–µ—à–∏–ª —Ç—É–¥–∞ –Ω–µ —Ö–æ–¥–∏—Ç—å.\n",
      "–Ø —Ä–µ—à–∏–ª —Ç—É–¥–∞ –Ω–µ —Ö–æ–¥–∏—Ç—å.\n",
      "\n",
      "–ú—ã —Å –¢–æ–º–æ–º –æ–±–∞ –µ–¥–µ–º.\n",
      "–ú—ã —Å –¢–æ–º–æ–º –æ–±–∞ –µ–¥–µ–º.\n",
      "\n",
      "–ö–∞–∫ –Ω–∞–º —ç—Ç–æ —Å–Ω–æ–≤–∞ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å?\n",
      "–ö–∞–∫ –Ω–∞–º –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å —ç—Ç–æ –≤ –¥–∞–ª—å–Ω–µ–π—à–µ–º?\n",
      "\n",
      "–í—ã –±—É–¥–µ—Ç–µ –∂–¥–∞—Ç—å?\n",
      "–ë—É–¥–µ—Ç–µ –∂–¥–∞—Ç—å?\n",
      "\n",
      "–≠—Ç–æ –∑–∞—Å—Ç–∞–≤–∏–ª–æ—Å—å –º–æ–∏ –≤–æ–ª–æ—Å—ã –Ω–∞ –∫–æ–Ω—Ü–µ –∫–æ–Ω—Ü–æ–≤.\n",
      "–£ –º–µ–Ω—è –æ—Ç —ç—Ç–æ–≥–æ –≤–æ–ª–æ—Å—ã –≤—Å—Ç–∞–ª–∏ –¥—ã–±–æ–º.\n",
      "\n",
      "–≠—Ç–æ –Ω–µ —Ö–æ—Ö–æ—Ö–æ.\n",
      "–≠—Ç–æ –Ω–µ —É—á–µ–Ω–∏–µ.\n",
      "\n",
      "–¢–æ–º –≥—Ä–æ–º–∫–æ –∑–∞–∫—Ä–∏—á–∞–ª.\n",
      "–¢–æ–º –≥—Ä–æ–º–∫–æ –∫–∞—à–ª—è–Ω—É–ª.\n",
      "\n",
      "–ß—Ç–æ —Ç—ã –≤—Å—ë –æ–¥–µ—Ç?\n",
      "–ö—É–¥–∞ —ç—Ç–æ –≤—ã –≤—Å–µ —Ç–∞–∫ –≤—ã—Ä—è–¥–∏–ª–∏—Å—å?\n",
      "\n",
      "–û–Ω–∞ —Å–ª–∏—à–∫–æ–º –±–æ–≥–∞—Ç–∞, —á—Ç–æ–±—ã —Å—Ç–∞—Ç—å –≤–æ—Ä–æ–º.\n",
      "–û–Ω–∞ —Å–ª–∏—à–∫–æ–º –±–æ–≥–∞—Ç–∞, —á—Ç–æ–±—ã —Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è –≤–æ—Ä–æ–º.\n",
      "\n",
      "–ß—Ç–æ —ç—Ç–æ –≥–æ–≤–æ—Ä—è—Ç –ë–∏–±–ª–∏—é?\n",
      "–ß—Ç–æ –ë–∏–±–ª–∏—è –≥–æ–≤–æ—Ä–∏—Ç –ø–æ —ç—Ç–æ–º—É –ø–æ–≤–æ–¥—É?\n",
      "\n",
      "–¢–æ–º - —Ö–∏–∂.\n",
      "–¢–æ–º - –∫—Ä—É–ø—å–µ.\n",
      "\n",
      "–≠—Ç–æ —Ö–≤–∞—Ç–∏—Ç –¥–æ–≤–æ–ª—å–Ω–æ —É–º–Ω—ã–π.\n",
      "–¢–æ—Ç –ø—Ä–æ–¥–∞–≤–µ—Ü –≤—ã–≥–ª—è–¥–∏—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —É–º–Ω—ã–º.\n",
      "\n",
      "–Ø —Å –¢–æ–º–æ–º –≤—Ä–µ–∑–∞–ª –º–∞—à–∏–Ω—É.\n",
      "–Ø –µ–¥—É —Å –¢–æ–º–æ–º –≤ –æ–¥–Ω–æ–π –º–∞—à–∏–Ω–µ.\n",
      "\n",
      "–ù–µ –º–µ—à–∞–π—Ç–µ –µ—ë.\n",
      "–ù–µ –ø–æ–æ—â—Ä—è–π—Ç–µ –µ—ë.\n",
      "\n",
      "–ü–æ—á–µ–º—É –î–∂–µ–π–Ω –ø–æ–µ—Ö–∞–ª–∞ –Ω–∞ —Å—Ç–∞–Ω—Ü–∏–∏?\n",
      "–ó–∞—á–µ–º –î–∂–µ–π–Ω –ø–æ–µ—Ö–∞–ª–∞ –Ω–∞ –≤–æ–∫–∑–∞–ª?\n",
      "\n",
      "–ù–µ –¥—É–º–∞—é, —á—Ç–æ –¢–æ–º –∑–∞—Ö–æ—á–µ—Ç —Å –≤–∞–º–∏ –≤ –ë–æ—Å—Ç–æ–Ω.\n",
      "–Ø –Ω–µ –¥—É–º–∞—é, —á—Ç–æ –¢–æ–º –∑–∞—Ö–æ—á–µ—Ç –ø–æ–µ—Ö–∞—Ç—å —Å —Ç–æ–±–æ–π –≤ –ë–æ—Å—Ç–æ–Ω.\n",
      "\n",
      "–ú—ç—Ä–∏ –≤ –∫—Ä–∞—Å–∏–≤–æ–π –∫—Ä–∞—Å–Ω–æ–π –ø–ª–∞—Ç—å–µ.\n",
      "–ù–∞ –ú—ç—Ä–∏ –∫—Ä–∞—Å–∏–≤–æ–µ –∫—Ä–∞—Å–Ω–æ–µ –ø–ª–∞—Ç—å–µ.\n",
      "\n",
      "–•–æ—Ç–µ–ª –±—ã —è –±—ã—Ç—å —Ç–∞–∫–∏–º –≤—ã—Å–æ–∫–∏–º, –∫–∞–∫ —Ç—ã.\n",
      "–ñ–∞–ª—å, —á—Ç–æ —è –Ω–µ —Ç–∞–∫–æ–π –≤—ã—Å–æ–∫–∏–π, –∫–∞–∫ —Ç—ã.\n",
      "\n",
      "–ù–µ–≤–µ–∂–ª–∏–≤–æ —É—Å—Ç–∞–≤–∏—Ç—å—Å—è.\n",
      "–ì–ª–∞–∑–µ—Ç—å –Ω–µ –≤–µ–∂–ª–∏–≤–æ.\n",
      "\n",
      "–≠—Ç–æ —á—É–≤—Å—Ç–≤–æ —Å–µ–±—è –≥–ª—É–ø–æ.\n",
      "–≠—Ç–∞ —Ç–∫–∞–Ω—å –≥–ª–∞–¥–∫–∞—è –Ω–∞ –æ—â—É–ø—å.\n",
      "\n",
      "–¢–æ–º –Ω–µ —Ç–∞–∫–æ–π –º–æ–ª–æ–¥.\n",
      "–¢–æ–º –Ω–µ —Ç–∞–∫–æ–π —É–∂ –∏ –º–æ–ª–æ–¥–æ–π.\n",
      "\n",
      "–£–¥–∏–≤–∫–∏ —Å–µ–π—á–∞—Å –∏–∑ –º–æ–¥—ã.\n",
      "–î–ª–∏–Ω–Ω—ã–µ —é–±–∫–∏ –≤—ã—à–ª–∏ –∏–∑ –º–æ–¥—ã.\n",
      "\n",
      "–Ø –Ω–µ —Å–º–æ–≥—É —É—á–∏—Ç—å—Å—è –±–µ–∑ —ç—Ç–æ–π –∫–Ω–∏–≥–∏.\n",
      "–ë–µ–∑ —ç—Ç–æ–π –∫–Ω–∏–≥–∏ —è –Ω–µ —Å–º–æ–≥—É —É—á–∏—Ç—å—Å—è.\n",
      "\n",
      "–ù–µ —Å–º–æ—Ç—Ä–∏ –≤ –∫–æ—Ä–æ–±–∫—É.\n",
      "–ù–µ –∑–∞–≥–ª—è–¥—ã–≤–∞–π—Ç–µ –≤ —è—â–∏–∫.\n",
      "\n",
      "–í—Å–µ–º –Ω—É–∂–Ω–æ —Å–µ–±—è –ª—é–±–∏—Ç—å.\n",
      "–ö–∞–∂–¥–æ–º—É –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —á—É–≤—Å—Ç–≤–æ–≤–∞—Ç—å —Å–µ–±—è –ª—é–±–∏–º—ã–º.\n",
      "\n",
      "–Ø –±—ã –ª—É—á—à–µ —É–º—Ä—é —Ç–µ–±—è –∑–∞–º—É–∂.\n",
      "–Ø —Å–∫–æ—Ä–µ–µ —É–º—Ä—É, —á–µ–º –∂–µ–Ω—é—Å—å –Ω–∞ —Ç–µ–±–µ.\n",
      "\n",
      "–ö—Ç–æ-—Ç–æ —Ö–æ—á–µ—Ç –º–µ–Ω—è —É–±–∏—Ç—å.\n",
      "–ö—Ç–æ-—Ç–æ —Ö–æ—á–µ—Ç –º–µ–Ω—è —É–±–∏—Ç—å.\n",
      "\n",
      "–Ø –¥–µ–ª–∞—é –º–∞–≥–∞–∑–∏–Ω –≤ —Ä—ã–Ω–∫–µ.\n",
      "–Ø –¥–µ–ª–∞—é –ø–æ–∫—É–ø–∫–∏ –Ω–∞ —Ä—ã–Ω–∫–µ.\n",
      "\n",
      "–ú—É–∑—ã–∫–∞ –∏–º–µ–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ.\n",
      "–†–∞–∑–º–µ—Ä –∏–º–µ–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ.\n",
      "\n",
      "–í—ã —É–∂–µ –µ–ª–∏ –¥–æ–º–∞?\n",
      "–¢—ã —É–∂–µ –ø–æ–µ–ª–∞ –¥–æ–º–∞?\n",
      "\n",
      "–û—Ç–∫—É–¥–∞ —Ç—ã –∑–Ω–∞–ª, —á—Ç–æ –¢–æ–º –±–æ–ª–µ–Ω?\n",
      "–û—Ç–∫—É–¥–∞ —Ç—ã —É–∑–Ω–∞–ª, —á—Ç–æ –¢–æ–º –±–æ–ª–µ–Ω?\n",
      "\n",
      "–° –∫–µ–º —Ç—ã —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞–ª?\n",
      "–° –∫–µ–º –≤—ã —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞–ª–∏?\n",
      "\n",
      "–¢–æ–º —Ö–≤–∞—Ç–∞–ª –¥–≤–∞ –¥–Ω—è.\n",
      "–¢–æ–º –¥–≤–∞ –¥–Ω—è —Ä–µ–ø–µ—Ç–∏—Ä–æ–≤–∞–ª.\n",
      "\n",
      "–¢—ã –≤–µ–¥—å –Ω–µ —Å–ø–µ—à–∏—à—å?\n",
      "–í—ã –∂–µ –Ω–µ —Ç–æ—Ä–æ–ø–∏—Ç–µ—Å—å?\n",
      "\n",
      "–ú–Ω–µ –Ω–∞–¥–æ –±—ã–ª–æ —Ç–µ–±–µ –ø–æ–∑–≤–æ–Ω–∏—Ç—å.\n",
      "–ú–Ω–µ –Ω–∞–¥–æ –±—ã–ª–æ —Ç–µ–±–µ –ø–æ–∑–≤–æ–Ω–∏—Ç—å.\n",
      "\n",
      "–í—ã –Ω–µ –∑–Ω–∞–ª–∏, —á—Ç–æ –¢–æ–º —Å–ø–∏—Ç?\n",
      "–í—ã –Ω–µ –∑–Ω–∞–ª–∏, —á—Ç–æ –¢–æ–º —Å–ø–∏—Ç?\n",
      "\n",
      "–û–Ω –ø–æ–±–ª–µ–¥–∞–ª —Å —Ö–æ—Ä–æ—à–æ.\n",
      "–û–Ω –ø–æ–±–ª–µ–¥–Ω–µ–ª –æ—Ç –∏—Å–ø—É–≥–∞.\n",
      "\n",
      "–û–Ω–∞ –æ–±–µ—â–∞–ª–∞.\n",
      "–û–Ω–∞ –æ–±–µ—â–∞–ª–∞.\n",
      "\n",
      "–ú—ç—Ä–∏, –ø–æ—Ö–æ–∂–µ, –Ω–µ —É–±–µ–¥–∏–ª–∞, —á—Ç–æ –µ–π –Ω–∞–¥–æ —ç—Ç–æ —Å–¥–µ–ª–∞—Ç—å.\n",
      "–ù–µ–ø–æ—Ö–æ–∂–µ, —á—Ç–æ –ú–∞—Ä–∏—è —É–≤–µ—Ä–µ–Ω–∞, —á—Ç–æ –µ–π –Ω—É–∂–Ω–æ –¥–µ–ª–∞—Ç—å —ç—Ç–æ.\n",
      "\n",
      "–ù–µ –¥—É–º–∞—é, —á—Ç–æ –¢–æ–º –∫–æ–≥–¥–∞-–Ω–∏–±—É–¥—å —Å–º–æ–∂–µ—Ç —Å–Ω–æ–≤–∞ —Ö–æ–¥–∏—Ç—å.\n",
      "–ù–µ –¥—É–º–∞—é, —á—Ç–æ –¢–æ–º –∫–æ–≥–¥–∞-–Ω–∏–±—É–¥—å —Å–º–æ–∂–µ—Ç –æ–ø—è—Ç—å —Ö–æ–¥–∏—Ç—å.\n",
      "\n",
      "–£ —Ç–µ–±—è –µ—Å—Ç—å?\n",
      "–û–Ω —É –≤–∞—Å?\n",
      "\n",
      "–Ø –ø—ã—Ç–∞–ª—Å—è —Ç–µ–±—è –∑–∞—â–∏—Ç–∏—Ç—å.\n",
      "–Ø –ø—ã—Ç–∞–ª—Å—è –∑–∞—â–∏—Ç–∏—Ç—å –≤–∞—Å.\n",
      "\n",
      "–í–∞—à –ø–∏—Å—å–º–æ —Å–ª–∏—à–∫–æ–º –ø–æ–∑–¥–Ω–æ –ø—Ä–∏—à—ë–ª.\n",
      "–¢–≤–æ—ë –ø–∏—Å—å–º–æ –ø—Ä–∏—à–ª–æ —Å–ª–∏—à–∫–æ–º –ø–æ–∑–¥–Ω–æ.\n",
      "\n",
      "–Ø –¥—É–º–∞—é, –¢–æ–º –º–µ–Ω—è –±–æ–ª–µ–Ω.\n",
      "–î—É–º–∞—é, –¢–æ–º–∞ –æ—Ç –º–µ–Ω—è —Ç–æ—à–Ω–∏—Ç.\n",
      "\n",
      "–ß–µ–ª–æ–≤–µ–∫ –≤—ã–∑–≤–∞–ª—Å—è, –∫–æ–≥–¥–∞ —Ç—ã –≤—ã—à–µ–ª.\n",
      "–ü–æ–∫–∞ —Ç–µ–±—è –Ω–µ –±—ã–ª–æ, –ø—Ä–∏—Ö–æ–¥–∏–ª –∫–∞–∫–æ–π-—Ç–æ –î–∂–æ–Ω—Å.\n",
      "\n",
      "–ö–∞–∫–∏–µ –∫–Ω–∏–≥–∏ –≤—ã —á–∏—Ç–∞–µ—Ç–µ?\n",
      "–ö–∞–∫–æ–≥–æ —Ä–æ–¥–∞ –∫–Ω–∏–≥–∏ —Ç—ã —á–∏—Ç–∞–µ—à—å?\n",
      "\n",
      "–û–Ω –∑–Ω–∞–µ—Ç, —á—Ç–æ —Ç—ã –∑–Ω–∞–µ—à—å?\n",
      "–û–Ω –∑–Ω–∞–µ—Ç, —á—Ç–æ —Ç—ã –∑–Ω–∞–µ—à—å?\n",
      "\n",
      "–Ø –Ω–µ –º–æ–≥—É –≤–∞—Å –∂–¥–∞—Ç—å.\n",
      "–ú–Ω–µ –Ω–µ —Ç–µ—Ä–ø–∏—Ç—Å—è —Ç–µ–±—è —É–≤–∏–¥–µ—Ç—å.\n",
      "\n",
      "–ù–∏–∫—Ç–æ –æ–±–æ –º–Ω–µ –Ω–µ –∑–∞–±–æ—Ç–∏—Ç—Å—è.\n",
      "–ù–∞ –º–µ–Ω—è –≤—Å–µ–º –Ω–∞–ø–ª–µ–≤–∞—Ç—å.\n",
      "\n",
      "–Ø —Å–ª—ã—à–∞–ª, –æ–Ω —É–º–µ—Ä.\n",
      "–Ø —Å–ª—ã—à–∞–ª, —á—Ç–æ –æ–Ω —É–º–µ—Ä.\n",
      "\n",
      "–£ –∫–æ–≥–æ –µ—Å—Ç—å –≥–ª–∞–≤–Ω–∞—è —Ä–æ–ª—å?\n",
      "–ö—Ç–æ –≤ –≥–ª–∞–≤–Ω–æ–π —Ä–æ–ª–∏?\n",
      "\n",
      "–ë–µ–¥–Ω–∞—è –¥–µ–≤—É—à–∫–∞ –±—ã–ª–∞ –≤ —Ç–æ–º, —á—Ç–æ–±—ã –±—ã—Ç—å —Å–º–µ—Ä—Ç–∏.\n",
      "–ë–µ–¥–Ω–∞—è –¥–µ–≤—É—à–∫–∞ –±—ã–ª–∞ –ø—Ä–∏ —Å–º–µ—Ä—Ç–∏.\n",
      "\n",
      "–¢–æ–º —Å–µ–≥–æ–¥–Ω—è –ø—Ä–∏–µ—Ö–∞–ª –¥–æ–º–æ–π –ø–æ–∑–∂–µ –æ–±—ã—á–Ω–æ–≥–æ.\n",
      "–°–µ–≥–æ–¥–Ω—è –¢–æ–º –¥–æ–±—Ä–∞–ª—Å—è –¥–æ –¥–æ–º–∞ –ø–æ–∑–∂–µ —á–µ–º –æ–±—ã—á–Ω–æ.\n",
      "\n",
      "–î—É–º–∞—é, —è –∑–Ω–∞—é, —á—Ç–æ —Ç–µ–ø–µ—Ä—å —Å–ª—É—á–∏—Ç—Å—è.\n",
      "–ö–∞–∂–µ—Ç—Å—è, —è –∑–Ω–∞—é, —á—Ç–æ —Å–µ–π—á–∞—Å –±—É–¥–µ—Ç.\n",
      "\n",
      "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Ö–æ–¥–∏—Ç–µ –≤ –±–∞–Ω–∫.\n",
      "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å—Ö–æ–¥–∏ –≤ –±–∞–Ω–∫.\n",
      "\n",
      "–ù–µ –∑–∞—Å—Ç–∞–≤–ª—è–π—Ç–µ –µ–≥–æ.\n",
      "–ù–µ –ø–æ–¥–Ω–∏–º–∞–π—Ç–µ –µ–≥–æ.\n",
      "\n",
      "–¢—ã –Ω–µ –ø—Ä–∞–≤.\n",
      "–¢—ã –æ—à–∏–±–∞–µ—à—å—Å—è.\n",
      "\n",
      "–ù–µ—Ç, –Ω–µ–±–æ –Ω–µ –±—É–¥–µ—Ç –Ω–∞ –Ω–∞—à—É —Ç–µ—Ä–ø–µ—é.\n",
      "–ù–µ—Ç, –Ω–µ–±–æ –Ω–µ —É–ø–∞–¥—ë—Ç –Ω–∞–º –Ω–∞ –≥–æ–ª–æ–≤—É.\n",
      "\n",
      "–¢–µ–±–µ –Ω–∞–¥–æ –±—ã–ª–æ –ø–æ–ø—Ä–æ—Å–∏—Ç—å —É –¢–æ–º–∞ –æ –ø–æ–º–æ—â–∏.\n",
      "–¢–µ–±–µ –Ω–∞–¥–æ –±—ã–ª–æ –ø–æ–ø—Ä–æ—Å–∏—Ç—å —É –¢–æ–º–∞ –ø—Ä–æ—â–µ–Ω–∏—è –∑–∞ —Ç–æ, —á—Ç–æ —Ç—ã –µ–≥–æ –æ–±–æ–∑–≤–∞–ª.\n",
      "\n",
      "–ì–æ—Ä–æ–¥ - —Ç—Ä–∏ –≥–æ—Ä—ã –∏–∑ –¥–µ—Ä–µ–≤–∞.\n",
      "–ì–æ—Ä–æ–¥ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç—Ä—ë—Ö –º–∏–ª—è—Ö –æ—Ç —Ç–æ–≥–æ –º–µ—Å—Ç–∞.\n",
      "\n",
      "–ü—Ä–∏–Ω–µ—Å–∏—Ç–µ —Ä–µ–±—ë–Ω–∫–∞ —Ç—Ä—É–¥–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å.\n",
      "–í–æ—Å–ø–∏—Ç–∞–Ω–∏–µ –¥–µ—Ç–µ–π ‚Äî —Ç—è–∂–µ–ª—ã–π —Ç—Ä—É–¥.\n",
      "\n",
      "–ù–µ —Ä–∞–∑–æ—á–∞—Ä—É–π—Å—è –≤ –æ–±–µ–∑—å—è–Ω–µ.\n",
      "–ù–µ –∑–ª–æ—É–ø–æ—Ç—Ä–µ–±–ª—è–π—Ç–µ –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏ –∑–Ω–∞–∫–∞–º–∏.\n",
      "\n",
      "–¢–æ–º –∫—É–ø–∏–ª –∫—É—Å–æ—á–µ–∫ –∫—É—Å–æ—á–∫–∏ –Ω–µ–¥–∞–ª–µ–∫–æ, –≥–¥–µ –∂–∏–≤—ë—Ç –ú—ç—Ä–∏.\n",
      "–¢–æ–º –∫—É–ø–∏–ª —É—á–∞—Å—Ç–æ–∫ –∑–µ–º–ª–∏ –Ω–µ–¥–∞–ª–µ–∫–æ –æ—Ç —Ç–æ–≥–æ –º–µ—Å—Ç–∞, –≥–¥–µ –∂–∏–≤—ë—Ç –ú—ç—Ä–∏.\n",
      "\n",
      "–í—ã –∑–Ω–∞–ª–∏, —á—Ç–æ —ç—Ç–æ –∂–∏–≤—ë—Ç –≤ —ç—Ç–æ–º –≥–æ—Ä–µ?\n",
      "–í—ã –∑–Ω–∞–ª–∏, —á—Ç–æ –Ω–∞ —ç—Ç–æ–π –≥–æ—Ä–µ –∂–∏–≤—É—Ç –ª–∏—Å–∏—Ü—ã?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(translations)):\n",
    "    print(translations[i])\n",
    "    print(targets[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a193d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['–¢–æ–º –ø—Ä–µ–∑–∏—Ä–∞–ª –ú—ç—Ä–∏.',\n",
       " '–û–Ω –æ–±–µ—â–∞–ª, —á—Ç–æ —Å–¥–µ–ª–∞–µ—Ç —ç—Ç–æ.',\n",
       " '–¢—ã –≤—ã–≥–ª—è–¥–∏—à—å –¥–æ–≤–æ–ª—å–Ω–æ–π.',\n",
       " '–ö–∞–∫ –ø—Ä–æ—à–ª–æ –∑–∞–Ω—è—Ç–∏–µ?',\n",
       " '–ö—Ç–æ –∑–≤–æ–Ω–∏–ª –≠–Ω–Ω?',\n",
       " '–ó–∞—Ç–æ—á–∏—Ç—å –µ–≥–æ –≤ —Ç–µ–º–Ω–∏—Ü—É!',\n",
       " '–ß–µ–≥–æ –µ—â—ë –¢–æ–º —Ö–æ—á–µ—Ç?',\n",
       " '–¢–æ–º —É—à—ë–ª —Ä–∞–Ω—å—à–µ.',\n",
       " '–¢–æ–º—É —Ä–∞–Ω–æ –≥–æ–ª–æ—Å–æ–≤–∞—Ç—å.',\n",
       " '–ú—ã –Ω–∞–π–¥—ë–º —Ä–µ—à–µ–Ω–∏–µ, —è —É–≤–µ—Ä–µ–Ω.',\n",
       " '–ö–æ–≥–¥–∞ —É –≤–∞—Å –ø–µ—Ä–≤—ã–π —É—Ä–æ–∫?',\n",
       " '–Ø –≤–∏–¥–µ–ª, –∫–∞–∫ –¢–æ–º —Å –ú—ç—Ä–∏ –¥–µ—Ä–∂–∞–ª–∏—Å—å –∑–∞ —Ä—É–∫–∏.',\n",
       " '–ù–µ –≥–æ–≤–æ—Ä–∏—Ç–µ –º–Ω–µ —Ç–æ–≥–æ, —á—Ç–æ —è –∏ —Ç–∞–∫ –∑–Ω–∞—é.',\n",
       " '–ï—Å–ª–∏ –±—ã –∂–µ–Ω—â–∏–Ω—ã –∑–Ω–∞–ª–∏, –∫–∞–∫ –º—ã –ø–æ –Ω–∏–º —Å–∫—É—á–∞–µ–º, –æ–Ω–∏ –±—ã —Ä–∞–Ω—å—à–µ —É—Ö–æ–¥–∏–ª–∏.',\n",
       " '–û—Ç–∫—É–¥–∞ –≤—ã –∑–Ω–∞–µ—Ç–µ, —á—Ç–æ —ç—Ç–æ –Ω–µ–ø—Ä–∞–≤–¥–∞?',\n",
       " '–ù–µ —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞–π—Ç–µ —Å –≤–æ–¥–∏—Ç–µ–ª–µ–º –∞–≤—Ç–æ–±—É—Å–∞ –≤–æ –≤—Ä–µ–º—è –¥–≤–∏–∂–µ–Ω–∏—è.',\n",
       " '–ú–æ–ª—á–∞–Ω–∏–µ –¢–æ–º–∞ –º–µ–Ω—è —É–¥–∏–≤–∏–ª–æ.',\n",
       " '–ì–¥–µ –±–ª–∏–∂–∞–π—à–∞—è –∞–≤—Ç–æ–±—É—Å–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞?',\n",
       " '–£ –º–µ–Ω—è –µ—â—ë –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –±—ã–ª–æ —Ç–∞–∫–æ–π —Å–∏–ª—å–Ω–æ–π –≥–æ–ª–æ–≤–Ω–æ–π –±–æ–ª–∏.',\n",
       " '–ú–æ–∂–Ω–æ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ç–≤–æ–∏–º —Ç—É–∞–ª–µ—Ç–æ–º?',\n",
       " '–¢–æ–º —Å–∫–∞–∑–∞–ª, —á—Ç–æ –Ω–∞–¥–µ–µ—Ç—Å—è, —á—Ç–æ –≤—ã —ç—Ç–æ —Å–¥–µ–ª–∞–µ—Ç–µ.',\n",
       " '–¢–æ–º –∏ –ú—ç—Ä–∏ –≤ –æ–¥–Ω–æ–π —É—á–µ–±–Ω–æ–π –≥—Ä—É–ø–ø–µ.',\n",
       " '–°–µ–≥–æ–¥–Ω—è —è –æ—á–µ–Ω—å —É—Å—Ç–∞–ª–∞.',\n",
       " '–Ø —Ö–æ—á—É –ø–æ–Ω—è—Ç—å –¢–æ–º–∞.',\n",
       " '–ù–æ–≥–∞ –æ–ø—è—Ç—å –∑–∞—Ç–µ–∫–ª–∞.',\n",
       " '–≠—Ç–æ —è —É—á—É –¢–æ–º–∞ —Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–æ–º—É.',\n",
       " '–ö–∞–∫–∏–µ –µ—Å—Ç—å –≤–∞—Ä–∏–∞–Ω—Ç—ã?',\n",
       " '–¢–æ–º –ø–æ—Å–º–æ—Ç—Ä–µ–ª –Ω–∞–≤–µ—Ä—Ö.',\n",
       " '–û–Ω –Ω–µ –≤—ã–≥–ª—è–¥–∏—Ç –æ—Å–æ–±–µ–Ω–Ω–æ —Å—á–∞—Å—Ç–ª–∏–≤—ã–º.',\n",
       " '–ü–æ–ª–æ–≤–∏–Ω–∞ —è–±–ª–æ–∫–∞ –±—ã–ª–∞ –≥–Ω–∏–ª–æ–π.',\n",
       " '–¢—ã —Å—Ç—Ä–∞–Ω–Ω—ã–π —á–µ–ª–æ–≤–µ–∫.',\n",
       " '–¢–µ–±–µ, –Ω–∞–≤–µ—Ä–Ω–æ–µ, –Ω–µ —Å—Ç–æ–∏—Ç –≥–æ–≤–æ—Ä–∏—Ç—å –¢–æ–º—É, —á—Ç–æ–±—ã –æ–Ω —ç—Ç–æ —Å–¥–µ–ª–∞–ª.',\n",
       " '–Ø –Ω–µ –∑–Ω–∞–ª, —á—Ç–æ —Ç—ã —É–º–µ–µ—à—å –∏–≥—Ä–∞—Ç—å –Ω–∞ —Ç—Ä–æ–º–±–æ–Ω–µ.',\n",
       " '–ü–∞—Ä–∞ –∑–≤–µ—Ä–µ–π –∏–≥—Ä–∞–ª–∞ –Ω–∞ –ª—É–≥—É.',\n",
       " '–ú–µ—Å—Ç–Ω—ã–µ –∂–∏—Ç–µ–ª–∏ –Ω–∞–∑—ã–≤–∞—é—Ç —ç—Ç—É —Ä–µ–∫—É \"–ª—é–¥–æ–µ–¥–æ–º\" –∏ –±–æ—è—Ç—Å—è –µ—ë.',\n",
       " '–ù–∞ —ç—Ç–æ–º —Å–∞–π—Ç–µ –º–Ω–æ–≥–æ –ø–æ–ª–µ–∑–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π.',\n",
       " '–Ø —Ä–µ—à–∏–ª —Ç—É–¥–∞ –Ω–µ —Ö–æ–¥–∏—Ç—å.',\n",
       " '–ú—ã —Å –¢–æ–º–æ–º –æ–±–∞ –µ–¥–µ–º.',\n",
       " '–ö–∞–∫ –Ω–∞–º –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å —ç—Ç–æ –≤ –¥–∞–ª—å–Ω–µ–π—à–µ–º?',\n",
       " '–ë—É–¥–µ—Ç–µ –∂–¥–∞—Ç—å?',\n",
       " '–£ –º–µ–Ω—è –æ—Ç —ç—Ç–æ–≥–æ –≤–æ–ª–æ—Å—ã –≤—Å—Ç–∞–ª–∏ –¥—ã–±–æ–º.',\n",
       " '–≠—Ç–æ –Ω–µ —É—á–µ–Ω–∏–µ.',\n",
       " '–¢–æ–º –≥—Ä–æ–º–∫–æ –∫–∞—à–ª—è–Ω—É–ª.',\n",
       " '–ö—É–¥–∞ —ç—Ç–æ –≤—ã –≤—Å–µ —Ç–∞–∫ –≤—ã—Ä—è–¥–∏–ª–∏—Å—å?',\n",
       " '–û–Ω–∞ —Å–ª–∏—à–∫–æ–º –±–æ–≥–∞—Ç–∞, —á—Ç–æ–±—ã —Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è –≤–æ—Ä–æ–º.',\n",
       " '–ß—Ç–æ –ë–∏–±–ª–∏—è –≥–æ–≤–æ—Ä–∏—Ç –ø–æ —ç—Ç–æ–º—É –ø–æ–≤–æ–¥—É?',\n",
       " '–¢–æ–º - –∫—Ä—É–ø—å–µ.',\n",
       " '–¢–æ—Ç –ø—Ä–æ–¥–∞–≤–µ—Ü –≤—ã–≥–ª—è–¥–∏—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —É–º–Ω—ã–º.',\n",
       " '–Ø –µ–¥—É —Å –¢–æ–º–æ–º –≤ –æ–¥–Ω–æ–π –º–∞—à–∏–Ω–µ.',\n",
       " '–ù–µ –ø–æ–æ—â—Ä—è–π—Ç–µ –µ—ë.',\n",
       " '–ó–∞—á–µ–º –î–∂–µ–π–Ω –ø–æ–µ—Ö–∞–ª–∞ –Ω–∞ –≤–æ–∫–∑–∞–ª?',\n",
       " '–Ø –Ω–µ –¥—É–º–∞—é, —á—Ç–æ –¢–æ–º –∑–∞—Ö–æ—á–µ—Ç –ø–æ–µ—Ö–∞—Ç—å —Å —Ç–æ–±–æ–π –≤ –ë–æ—Å—Ç–æ–Ω.',\n",
       " '–ù–∞ –ú—ç—Ä–∏ –∫—Ä–∞—Å–∏–≤–æ–µ –∫—Ä–∞—Å–Ω–æ–µ –ø–ª–∞—Ç—å–µ.',\n",
       " '–ñ–∞–ª—å, —á—Ç–æ —è –Ω–µ —Ç–∞–∫–æ–π –≤—ã—Å–æ–∫–∏–π, –∫–∞–∫ —Ç—ã.',\n",
       " '–ì–ª–∞–∑–µ—Ç—å –Ω–µ –≤–µ–∂–ª–∏–≤–æ.',\n",
       " '–≠—Ç–∞ —Ç–∫–∞–Ω—å –≥–ª–∞–¥–∫–∞—è –Ω–∞ –æ—â—É–ø—å.',\n",
       " '–¢–æ–º –Ω–µ —Ç–∞–∫–æ–π —É–∂ –∏ –º–æ–ª–æ–¥–æ–π.',\n",
       " '–î–ª–∏–Ω–Ω—ã–µ —é–±–∫–∏ –≤—ã—à–ª–∏ –∏–∑ –º–æ–¥—ã.',\n",
       " '–ë–µ–∑ —ç—Ç–æ–π –∫–Ω–∏–≥–∏ —è –Ω–µ —Å–º–æ–≥—É —É—á–∏—Ç—å—Å—è.',\n",
       " '–ù–µ –∑–∞–≥–ª—è–¥—ã–≤–∞–π—Ç–µ –≤ —è—â–∏–∫.',\n",
       " '–ö–∞–∂–¥–æ–º—É –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —á—É–≤—Å—Ç–≤–æ–≤–∞—Ç—å —Å–µ–±—è –ª—é–±–∏–º—ã–º.',\n",
       " '–Ø —Å–∫–æ—Ä–µ–µ —É–º—Ä—É, —á–µ–º –∂–µ–Ω—é—Å—å –Ω–∞ —Ç–µ–±–µ.',\n",
       " '–ö—Ç–æ-—Ç–æ —Ö–æ—á–µ—Ç –º–µ–Ω—è —É–±–∏—Ç—å.',\n",
       " '–Ø –¥–µ–ª–∞—é –ø–æ–∫—É–ø–∫–∏ –Ω–∞ —Ä—ã–Ω–∫–µ.',\n",
       " '–†–∞–∑–º–µ—Ä –∏–º–µ–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ.',\n",
       " '–¢—ã —É–∂–µ –ø–æ–µ–ª–∞ –¥–æ–º–∞?',\n",
       " '–û—Ç–∫—É–¥–∞ —Ç—ã —É–∑–Ω–∞–ª, —á—Ç–æ –¢–æ–º –±–æ–ª–µ–Ω?',\n",
       " '–° –∫–µ–º –≤—ã —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞–ª–∏?',\n",
       " '–¢–æ–º –¥–≤–∞ –¥–Ω—è —Ä–µ–ø–µ—Ç–∏—Ä–æ–≤–∞–ª.',\n",
       " '–í—ã –∂–µ –Ω–µ —Ç–æ—Ä–æ–ø–∏—Ç–µ—Å—å?',\n",
       " '–ú–Ω–µ –Ω–∞–¥–æ –±—ã–ª–æ —Ç–µ–±–µ –ø–æ–∑–≤–æ–Ω–∏—Ç—å.',\n",
       " '–í—ã –Ω–µ –∑–Ω–∞–ª–∏, —á—Ç–æ –¢–æ–º —Å–ø–∏—Ç?',\n",
       " '–û–Ω –ø–æ–±–ª–µ–¥–Ω–µ–ª –æ—Ç –∏—Å–ø—É–≥–∞.',\n",
       " '–û–Ω–∞ –æ–±–µ—â–∞–ª–∞.',\n",
       " '–ù–µ–ø–æ—Ö–æ–∂–µ, —á—Ç–æ –ú–∞—Ä–∏—è —É–≤–µ—Ä–µ–Ω–∞, —á—Ç–æ –µ–π –Ω—É–∂–Ω–æ –¥–µ–ª–∞—Ç—å —ç—Ç–æ.',\n",
       " '–ù–µ –¥—É–º–∞—é, —á—Ç–æ –¢–æ–º –∫–æ–≥–¥–∞-–Ω–∏–±—É–¥—å —Å–º–æ–∂–µ—Ç –æ–ø—è—Ç—å —Ö–æ–¥–∏—Ç—å.',\n",
       " '–û–Ω —É –≤–∞—Å?',\n",
       " '–Ø –ø—ã—Ç–∞–ª—Å—è –∑–∞—â–∏—Ç–∏—Ç—å –≤–∞—Å.',\n",
       " '–¢–≤–æ—ë –ø–∏—Å—å–º–æ –ø—Ä–∏—à–ª–æ —Å–ª–∏—à–∫–æ–º –ø–æ–∑–¥–Ω–æ.',\n",
       " '–î—É–º–∞—é, –¢–æ–º–∞ –æ—Ç –º–µ–Ω—è —Ç–æ—à–Ω–∏—Ç.',\n",
       " '–ü–æ–∫–∞ —Ç–µ–±—è –Ω–µ –±—ã–ª–æ, –ø—Ä–∏—Ö–æ–¥–∏–ª –∫–∞–∫–æ–π-—Ç–æ –î–∂–æ–Ω—Å.',\n",
       " '–ö–∞–∫–æ–≥–æ —Ä–æ–¥–∞ –∫–Ω–∏–≥–∏ —Ç—ã —á–∏—Ç–∞–µ—à—å?',\n",
       " '–û–Ω –∑–Ω–∞–µ—Ç, —á—Ç–æ —Ç—ã –∑–Ω–∞–µ—à—å?',\n",
       " '–ú–Ω–µ –Ω–µ —Ç–µ—Ä–ø–∏—Ç—Å—è —Ç–µ–±—è —É–≤–∏–¥–µ—Ç—å.',\n",
       " '–ù–∞ –º–µ–Ω—è –≤—Å–µ–º –Ω–∞–ø–ª–µ–≤–∞—Ç—å.',\n",
       " '–Ø —Å–ª—ã—à–∞–ª, —á—Ç–æ –æ–Ω —É–º–µ—Ä.',\n",
       " '–ö—Ç–æ –≤ –≥–ª–∞–≤–Ω–æ–π —Ä–æ–ª–∏?',\n",
       " '–ë–µ–¥–Ω–∞—è –¥–µ–≤—É—à–∫–∞ –±—ã–ª–∞ –ø—Ä–∏ —Å–º–µ—Ä—Ç–∏.',\n",
       " '–°–µ–≥–æ–¥–Ω—è –¢–æ–º –¥–æ–±—Ä–∞–ª—Å—è –¥–æ –¥–æ–º–∞ –ø–æ–∑–∂–µ —á–µ–º –æ–±—ã—á–Ω–æ.',\n",
       " '–ö–∞–∂–µ—Ç—Å—è, —è –∑–Ω–∞—é, —á—Ç–æ —Å–µ–π—á–∞—Å –±—É–¥–µ—Ç.',\n",
       " '–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å—Ö–æ–¥–∏ –≤ –±–∞–Ω–∫.',\n",
       " '–ù–µ –ø–æ–¥–Ω–∏–º–∞–π—Ç–µ –µ–≥–æ.',\n",
       " '–¢—ã –æ—à–∏–±–∞–µ—à—å—Å—è.',\n",
       " '–ù–µ—Ç, –Ω–µ–±–æ –Ω–µ —É–ø–∞–¥—ë—Ç –Ω–∞–º –Ω–∞ –≥–æ–ª–æ–≤—É.',\n",
       " '–¢–µ–±–µ –Ω–∞–¥–æ –±—ã–ª–æ –ø–æ–ø—Ä–æ—Å–∏—Ç—å —É –¢–æ–º–∞ –ø—Ä–æ—â–µ–Ω–∏—è –∑–∞ —Ç–æ, —á—Ç–æ —Ç—ã –µ–≥–æ –æ–±–æ–∑–≤–∞–ª.',\n",
       " '–ì–æ—Ä–æ–¥ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç—Ä—ë—Ö –º–∏–ª—è—Ö –æ—Ç —Ç–æ–≥–æ –º–µ—Å—Ç–∞.',\n",
       " '–í–æ—Å–ø–∏—Ç–∞–Ω–∏–µ –¥–µ—Ç–µ–π ‚Äî —Ç—è–∂–µ–ª—ã–π —Ç—Ä—É–¥.',\n",
       " '–ù–µ –∑–ª–æ—É–ø–æ—Ç—Ä–µ–±–ª—è–π—Ç–µ –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏ –∑–Ω–∞–∫–∞–º–∏.',\n",
       " '–¢–æ–º –∫—É–ø–∏–ª —É—á–∞—Å—Ç–æ–∫ –∑–µ–º–ª–∏ –Ω–µ–¥–∞–ª–µ–∫–æ –æ—Ç —Ç–æ–≥–æ –º–µ—Å—Ç–∞, –≥–¥–µ –∂–∏–≤—ë—Ç –ú—ç—Ä–∏.',\n",
       " '–í—ã –∑–Ω–∞–ª–∏, —á—Ç–æ –Ω–∞ —ç—Ç–æ–π –≥–æ—Ä–µ –∂–∏–≤—É—Ç –ª–∏—Å–∏—Ü—ã?']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3412bdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/sutclw/anaconda3/envs/torch/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "backuplogs\t\t      logs\t     translation\r\n",
      "build\t\t\t      main.py\t     translation.egg-info\r\n",
      "Encoder_Decoder_ru.ipynb      notebooks      Translation.ipynb\r\n",
      "en_ru_transformer_8epochs.pt  setup.py\t     Untitled.ipynb\r\n",
      "Evaluation.ipynb\t      test.csv\t     WordStressTransformer.ipynb\r\n",
      "Evaluation_pytorch.ipynb      Testing.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91aa2f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(62519, 64)\n",
       "    (pos_encoding): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer_blocks): Sequential(\n",
       "      (0): EncoderBlock(\n",
       "        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiHeadAttention(\n",
       "          (key): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (query): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (value): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (fc): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (ann): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): EncoderBlock(\n",
       "        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiHeadAttention(\n",
       "          (key): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (query): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (value): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (fc): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (ann): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): EncoderBlock(\n",
       "        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiHeadAttention(\n",
       "          (key): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (query): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (value): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (fc): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (ann): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): EncoderBlock(\n",
       "        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiHeadAttention(\n",
       "          (key): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (query): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (value): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (fc): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (ann): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(62519, 64)\n",
       "    (pos_encoding): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer_blocks): Sequential(\n",
       "      (0): DecoderBlock(\n",
       "        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (key): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (query): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (value): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (fc): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (key): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (query): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (value): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (fc): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (ann): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (key): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (query): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (value): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (fc): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (key): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (query): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (value): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (fc): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (ann): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (key): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (query): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (value): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (fc): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (key): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (query): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (value): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (fc): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (ann): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln3): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha1): MultiHeadAttention(\n",
       "          (key): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (query): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (value): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (fc): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (mha2): MultiHeadAttention(\n",
       "          (key): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (query): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (value): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (fc): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (ann): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (fc): Linear(in_features=64, out_features=62519, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.load_state_dict(torch.load('en_ru_transformer_8epochs.pt'))\n",
    "transformer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "448365bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = []\n",
    "targets = []\n",
    "bertscores = []\n",
    "bleuscores = []\n",
    "for  i in range(100):\n",
    "    translations.append(translate(split['test'][i][l1])[:-4])\n",
    "    targets.append(split['test'][i][l2])\n",
    "    score =bert_metric.compute(predictions=[translations[i]], references=[targets[i]], lang=\"ru\")['f1']\n",
    "    bertscores.append(score)\n",
    "    score =bleu_metric.compute(predictions=[translations[i]], references=[[targets[i]]])['score']\n",
    "    bleuscores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9baa6a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['–¢–æ–º –ø—Ä–µ–∑–∏—Ä–∞–ª –ú—ç—Ä–∏.',\n",
       " '–û–Ω –æ–±–µ—â–∞–ª, —á—Ç–æ —Å–¥–µ–ª–∞–µ—Ç —ç—Ç–æ.',\n",
       " '–¢—ã –ø–æ—Ö–æ–∂ –Ω–∞ –¥–æ–≤–æ–ª—å–Ω—ã.',\n",
       " '–ö–∞–∫ –±—ã–ª–∞ —Ç–≤–æ–π —É—Ä–æ–∫?',\n",
       " '–ö—Ç–æ –≤—ã–∑–≤–∞–ª –ê–Ω–Ω–∞?',\n",
       " '–ó–∞–π–º–∏ –µ–≥–æ –≤ —Å—É—Ö!',\n",
       " '–ß–µ–≥–æ –µ—â—ë –¢–æ–º —Ö–æ—á–µ—Ç?',\n",
       " '–¢–æ–º —É—à—ë–ª —Ä–∞–Ω—å—à–µ.',\n",
       " '–¢–æ–º —Å–ª–∏—à–∫–æ–º –º–æ–ª–æ–¥, —á—Ç–æ–±—ã –≥–æ–ª–æ—Å–æ–≤–∞—Ç—å.',\n",
       " '–ú—ã –Ω–∞–π–¥—ë–º —Ä–µ—à–µ–Ω–∏–µ, —è —É–≤–µ—Ä–µ–Ω.',\n",
       " '–ö–æ–≥–¥–∞ —Ç–≤–æ–π –ø–µ—Ä–≤—ã–π –∫–ª–∞—Å—Å?',\n",
       " '–Ø –≤–∏–¥–µ–ª, –∫–∞–∫ –¢–æ–º –∏ –ú—ç—Ä–∏ –¥–µ—Ä–∂–∞–ª–∏—Å—å —Ä—É–∫–∏.',\n",
       " '–ù–µ –≥–æ–≤–æ—Ä–∏ –º–Ω–µ, —á—Ç–æ —è —É–∂–µ –∑–Ω–∞—é.',\n",
       " '–ï—Å–ª–∏ –±—ã –∂–µ–Ω—â–∏–Ω—ã –∑–Ω–∞–ª–∏, —Å–∫–æ–ª—å–∫–æ –±—ã –º—ã –ø–æ –Ω–µ–º—É –º–Ω–æ–≥–æ —Ä–∞–∑ —Å–∫—É—á–∞–ª–∏, –æ–Ω–∏ –±—ã —É—à–ª–∏.',\n",
       " '–û—Ç–∫—É–¥–∞ —Ç—ã –∑–Ω–∞–µ—à—å, —á—Ç–æ —ç—Ç–æ –Ω–µ–ø—Ä–∞–≤–¥–∞?',\n",
       " '–ù–µ –≥–æ–≤–æ—Ä–∏ —Å –∞–≤—Ç–æ–±—É—Å–æ–º, –ø–æ–∫–∞ –æ–Ω –µ–¥–µ—Ç –Ω–∞ –∞–≤—Ç–æ–±—É—Å–µ.',\n",
       " '–°–ø–æ–∫–æ—è–¥—å –¢–æ–º–∞ —É–¥–∏–≤–∏–ª –º–µ–Ω—è.',\n",
       " '–ì–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –±–ª–∏–∂–∞–π—à–∏–π –∞–≤—Ç–æ–±—É—Å?',\n",
       " '–£ –º–µ–Ω—è –Ω–∏–∫–æ–≥–¥–∞ —Ä–∞–Ω—å—à–µ –Ω–µ –±—ã–ª–æ –±–æ–ª–∏—Ç –±–æ–ª–∏—Ç –±–æ–ª–∏—Ç.',\n",
       " '–ú–æ–∂–Ω–æ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤–∞—à–µ–π —Ç—É–∞–ª–µ—Ç–æ–º?',\n",
       " '–¢–æ–º —Å–∫–∞–∑–∞–ª, —á—Ç–æ –Ω–∞–¥–µ–µ—Ç—Å—è, —á—Ç–æ –≤—ã —ç—Ç–æ —Å–¥–µ–ª–∞–µ—Ç–µ.',\n",
       " '–¢–æ–º –∏ –ú—ç—Ä–∏ –∏–∑—É—á–∞—é—Ç —Ç–æ –∂–µ –≥—Ä—É–ø–ø–µ.',\n",
       " '–Ø —Å–µ–≥–æ–¥–Ω—è –æ—á–µ–Ω—å —É—Å—Ç–∞–ª.',\n",
       " '–Ø —Ö–æ—á—É –ø–æ–Ω—è—Ç—å –¢–æ–º–∞.',\n",
       " '–ú–æ—è –Ω–æ–≥–∞ –æ–ø—è—Ç—å —Å–ø–∏—Ç!',\n",
       " '–≠—Ç–æ —è –ø—Ä–µ–ø–æ–¥–∞–≤–∞–ª –¢–æ–º–∞ —Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π.',\n",
       " '–ö–∞–∫–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç—ã?',\n",
       " '–¢–æ–º –ø–æ—Å–º–æ—Ç—Ä–µ–ª.',\n",
       " '–û–Ω –Ω–µ –≤—ã–≥–ª—è–¥–∏—Ç –æ—á–µ–Ω—å —Å—á–∞—Å—Ç–ª–∏–≤—ã–º.',\n",
       " '–ü–æ–ª–æ–≤–æ—Ä–∞ —è–±–ª–æ–∫–æ –±—ã–ª –≥–∞–ª—Å—Ç–æ—Ç.',\n",
       " '–¢—ã —Å—Ç—Ä–∞–Ω–Ω—ã–π —á–µ–ª–æ–≤–µ–∫.',\n",
       " '–¢–µ–±–µ, –Ω–∞–≤–µ—Ä–Ω–æ–µ, –Ω–µ —Å—Ç–æ–∏—Ç –≥–æ–≤–æ—Ä–∏—Ç—å –¢–æ–º—É, —á—Ç–æ–±—ã –æ–Ω —ç—Ç–æ —Å–¥–µ–ª–∞–ª.',\n",
       " '–Ø –Ω–µ –∑–Ω–∞–ª, —á—Ç–æ —Ç—ã —É–º–µ–µ—à—å –∏–≥—Ä–∞—Ç—å –Ω–∞ –∫–∞—Ö–±–æ–Ω–µ.',\n",
       " '–ù–∞ –º–µ–Ω—è –∏–≥—Ä–∞–ª–∏ –º–∞–ª–æ –∂–∏–≤–æ—Ç–Ω—ã—Ö.',\n",
       " '–†–µ–º–æ–±–∏–ª—å –Ω–∞–∑—ã–≤–∞—é—Ç —ç—Ç—É —Ä–µ–∫—É \"—Å–∏–¥–∫—É –∏ —Å—Ç—Ä–∞—Ö.',\n",
       " '–í —ç—Ç–æ–º —Å–∞–π—Ç–µ –º–Ω–æ–≥–æ –∏–¥–µ–π.',\n",
       " '–Ø —Ä–µ—à–∏–ª —Ç—É–¥–∞ –Ω–µ —Ö–æ–¥–∏—Ç—å.',\n",
       " '–ú—ã —Å –¢–æ–º–æ–º –æ–±–∞ –µ–¥–µ–º.',\n",
       " '–ö–∞–∫ –Ω–∞–º —ç—Ç–æ —Å–Ω–æ–≤–∞ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å?',\n",
       " '–í—ã –±—É–¥–µ—Ç–µ –∂–¥–∞—Ç—å?',\n",
       " '–≠—Ç–æ –∑–∞—Å—Ç–∞–≤–∏–ª–æ—Å—å –º–æ–∏ –≤–æ–ª–æ—Å—ã –Ω–∞ –∫–æ–Ω—Ü–µ –∫–æ–Ω—Ü–æ–≤.',\n",
       " '–≠—Ç–æ –Ω–µ —Ö–æ—Ö–æ—Ö–æ.',\n",
       " '–¢–æ–º –≥—Ä–æ–º–∫–æ –∑–∞–∫—Ä–∏—á–∞–ª.',\n",
       " '–ß—Ç–æ —Ç—ã –≤—Å—ë –æ–¥–µ—Ç?',\n",
       " '–û–Ω–∞ —Å–ª–∏—à–∫–æ–º –±–æ–≥–∞—Ç–∞, —á—Ç–æ–±—ã —Å—Ç–∞—Ç—å –≤–æ—Ä–æ–º.',\n",
       " '–ß—Ç–æ —ç—Ç–æ –≥–æ–≤–æ—Ä—è—Ç –ë–∏–±–ª–∏—é?',\n",
       " '–¢–æ–º - —Ö–∏–∂.',\n",
       " '–≠—Ç–æ —Ö–≤–∞—Ç–∏—Ç –¥–æ–≤–æ–ª—å–Ω–æ —É–º–Ω—ã–π.',\n",
       " '–Ø —Å –¢–æ–º–æ–º –≤—Ä–µ–∑–∞–ª –º–∞—à–∏–Ω—É.',\n",
       " '–ù–µ –º–µ—à–∞–π—Ç–µ –µ—ë.',\n",
       " '–ü–æ—á–µ–º—É –î–∂–µ–π–Ω –ø–æ–µ—Ö–∞–ª–∞ –Ω–∞ —Å—Ç–∞–Ω—Ü–∏–∏?',\n",
       " '–ù–µ –¥—É–º–∞—é, —á—Ç–æ –¢–æ–º –∑–∞—Ö–æ—á–µ—Ç —Å –≤–∞–º–∏ –≤ –ë–æ—Å—Ç–æ–Ω.',\n",
       " '–ú—ç—Ä–∏ –≤ –∫—Ä–∞—Å–∏–≤–æ–π –∫—Ä–∞—Å–Ω–æ–π –ø–ª–∞—Ç—å–µ.',\n",
       " '–•–æ—Ç–µ–ª –±—ã —è –±—ã—Ç—å —Ç–∞–∫–∏–º –≤—ã—Å–æ–∫–∏–º, –∫–∞–∫ —Ç—ã.',\n",
       " '–ù–µ–≤–µ–∂–ª–∏–≤–æ —É—Å—Ç–∞–≤–∏—Ç—å—Å—è.',\n",
       " '–≠—Ç–æ —á—É–≤—Å—Ç–≤–æ —Å–µ–±—è –≥–ª—É–ø–æ.',\n",
       " '–¢–æ–º –Ω–µ —Ç–∞–∫–æ–π –º–æ–ª–æ–¥.',\n",
       " '–£–¥–∏–≤–∫–∏ —Å–µ–π—á–∞—Å –∏–∑ –º–æ–¥—ã.',\n",
       " '–Ø –Ω–µ —Å–º–æ–≥—É —É—á–∏—Ç—å—Å—è –±–µ–∑ —ç—Ç–æ–π –∫–Ω–∏–≥–∏.',\n",
       " '–ù–µ —Å–º–æ—Ç—Ä–∏ –≤ –∫–æ—Ä–æ–±–∫—É.',\n",
       " '–í—Å–µ–º –Ω—É–∂–Ω–æ —Å–µ–±—è –ª—é–±–∏—Ç—å.',\n",
       " '–Ø –±—ã –ª—É—á—à–µ —É–º—Ä—é —Ç–µ–±—è –∑–∞–º—É–∂.',\n",
       " '–ö—Ç–æ-—Ç–æ —Ö–æ—á–µ—Ç –º–µ–Ω—è —É–±–∏—Ç—å.',\n",
       " '–Ø –¥–µ–ª–∞—é –º–∞–≥–∞–∑–∏–Ω –≤ —Ä—ã–Ω–∫–µ.',\n",
       " '–ú—É–∑—ã–∫–∞ –∏–º–µ–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ.',\n",
       " '–í—ã —É–∂–µ –µ–ª–∏ –¥–æ–º–∞?',\n",
       " '–û—Ç–∫—É–¥–∞ —Ç—ã –∑–Ω–∞–ª, —á—Ç–æ –¢–æ–º –±–æ–ª–µ–Ω?',\n",
       " '–° –∫–µ–º —Ç—ã —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞–ª?',\n",
       " '–¢–æ–º —Ö–≤–∞—Ç–∞–ª –¥–≤–∞ –¥–Ω—è.',\n",
       " '–¢—ã –≤–µ–¥—å –Ω–µ —Å–ø–µ—à–∏—à—å?',\n",
       " '–ú–Ω–µ –Ω–∞–¥–æ –±—ã–ª–æ —Ç–µ–±–µ –ø–æ–∑–≤–æ–Ω–∏—Ç—å.',\n",
       " '–í—ã –Ω–µ –∑–Ω–∞–ª–∏, —á—Ç–æ –¢–æ–º —Å–ø–∏—Ç?',\n",
       " '–û–Ω –ø–æ–±–ª–µ–¥–∞–ª —Å —Ö–æ—Ä–æ—à–æ.',\n",
       " '–û–Ω–∞ –æ–±–µ—â–∞–ª–∞.',\n",
       " '–ú—ç—Ä–∏, –ø–æ—Ö–æ–∂–µ, –Ω–µ —É–±–µ–¥–∏–ª–∞, —á—Ç–æ –µ–π –Ω–∞–¥–æ —ç—Ç–æ —Å–¥–µ–ª–∞—Ç—å.',\n",
       " '–ù–µ –¥—É–º–∞—é, —á—Ç–æ –¢–æ–º –∫–æ–≥–¥–∞-–Ω–∏–±—É–¥—å —Å–º–æ–∂–µ—Ç —Å–Ω–æ–≤–∞ —Ö–æ–¥–∏—Ç—å.',\n",
       " '–£ —Ç–µ–±—è –µ—Å—Ç—å?',\n",
       " '–Ø –ø—ã—Ç–∞–ª—Å—è —Ç–µ–±—è –∑–∞—â–∏—Ç–∏—Ç—å.',\n",
       " '–í–∞—à –ø–∏—Å—å–º–æ —Å–ª–∏—à–∫–æ–º –ø–æ–∑–¥–Ω–æ –ø—Ä–∏—à—ë–ª.',\n",
       " '–Ø –¥—É–º–∞—é, –¢–æ–º –º–µ–Ω—è –±–æ–ª–µ–Ω.',\n",
       " '–ß–µ–ª–æ–≤–µ–∫ –≤—ã–∑–≤–∞–ª—Å—è, –∫–æ–≥–¥–∞ —Ç—ã –≤—ã—à–µ–ª.',\n",
       " '–ö–∞–∫–∏–µ –∫–Ω–∏–≥–∏ –≤—ã —á–∏—Ç–∞–µ—Ç–µ?',\n",
       " '–û–Ω –∑–Ω–∞–µ—Ç, —á—Ç–æ —Ç—ã –∑–Ω–∞–µ—à—å?',\n",
       " '–Ø –Ω–µ –º–æ–≥—É –≤–∞—Å –∂–¥–∞—Ç—å.',\n",
       " '–ù–∏–∫—Ç–æ –æ–±–æ –º–Ω–µ –Ω–µ –∑–∞–±–æ—Ç–∏—Ç—Å—è.',\n",
       " '–Ø —Å–ª—ã—à–∞–ª, –æ–Ω —É–º–µ—Ä.',\n",
       " '–£ –∫–æ–≥–æ –µ—Å—Ç—å –≥–ª–∞–≤–Ω–∞—è —Ä–æ–ª—å?',\n",
       " '–ë–µ–¥–Ω–∞—è –¥–µ–≤—É—à–∫–∞ –±—ã–ª–∞ –≤ —Ç–æ–º, —á—Ç–æ–±—ã –±—ã—Ç—å —Å–º–µ—Ä—Ç–∏.',\n",
       " '–¢–æ–º —Å–µ–≥–æ–¥–Ω—è –ø—Ä–∏–µ—Ö–∞–ª –¥–æ–º–æ–π –ø–æ–∑–∂–µ –æ–±—ã—á–Ω–æ–≥–æ.',\n",
       " '–î—É–º–∞—é, —è –∑–Ω–∞—é, —á—Ç–æ —Ç–µ–ø–µ—Ä—å —Å–ª—É—á–∏—Ç—Å—è.',\n",
       " '–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Ö–æ–¥–∏—Ç–µ –≤ –±–∞–Ω–∫.',\n",
       " '–ù–µ –∑–∞—Å—Ç–∞–≤–ª—è–π—Ç–µ –µ–≥–æ.',\n",
       " '–¢—ã –Ω–µ –ø—Ä–∞–≤.',\n",
       " '–ù–µ—Ç, –Ω–µ–±–æ –Ω–µ –±—É–¥–µ—Ç –Ω–∞ –Ω–∞—à—É —Ç–µ—Ä–ø–µ—é.',\n",
       " '–¢–µ–±–µ –Ω–∞–¥–æ –±—ã–ª–æ –ø–æ–ø—Ä–æ—Å–∏—Ç—å —É –¢–æ–º–∞ –æ –ø–æ–º–æ—â–∏.',\n",
       " '–ì–æ—Ä–æ–¥ - —Ç—Ä–∏ –≥–æ—Ä—ã –∏–∑ –¥–µ—Ä–µ–≤–∞.',\n",
       " '–ü—Ä–∏–Ω–µ—Å–∏—Ç–µ —Ä–µ–±—ë–Ω–∫–∞ —Ç—Ä—É–¥–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å.',\n",
       " '–ù–µ —Ä–∞–∑–æ—á–∞—Ä—É–π—Å—è –≤ –æ–±–µ–∑—å—è–Ω–µ.',\n",
       " '–¢–æ–º –∫—É–ø–∏–ª –∫—É—Å–æ—á–µ–∫ –∫—É—Å–æ—á–∫–∏ –Ω–µ–¥–∞–ª–µ–∫–æ, –≥–¥–µ –∂–∏–≤—ë—Ç –ú—ç—Ä–∏.',\n",
       " '–í—ã –∑–Ω–∞–ª–∏, —á—Ç–æ —ç—Ç–æ –∂–∏–≤—ë—Ç –≤ —ç—Ç–æ–º –≥–æ—Ä–µ?']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c013b0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ÁßÅ„ÅØ<unk> „ÅåÂ•Ω„Åç„Åß„Åô<unk> </s>'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"I like rice\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a60972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    n_h = trial.suggest_int(\"n_heads\", 4, 8, 1)\n",
    "    n_l = trial.suggest_int(\"n_layers\", 2, 8, 1)\n",
    "    #n_mod = trial.suggest_int(\"n_layers\", 64, 128, 64)\n",
    "   \n",
    "    encoder = Encoder(vocab_size=tokenizer.vocab_size + 1,\n",
    "                      max_len=512,\n",
    "                      d_k=16,\n",
    "                      d_model=128,\n",
    "                      n_heads=n_h,\n",
    "                      n_layers=n_l,\n",
    "                      dropout_prob=0.1)\n",
    "    decoder = Decoder(vocab_size=tokenizer.vocab_size + 1,\n",
    "                      max_len=512,\n",
    "                      d_k=16,\n",
    "                      d_model=128,\n",
    "                      n_heads=n_h,\n",
    "                      n_layers=n_l,\n",
    "                      dropout_prob=0.1)\n",
    "    transformer = Transformer(encoder, decoder)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "    return(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b36214dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input_sentence, model):\n",
    "  # get encoder output first\n",
    "    enc_input = tokenizer(input_sentence, return_tensors='pt').to(device)\n",
    "    #print(device)\n",
    "    enc_output = model.encoder(enc_input['input_ids'], enc_input['attention_mask'])\n",
    "\n",
    "    # setup initial decoder input\n",
    "    dec_input_ids = torch.tensor([[ int(tokenizer.vocab_size)]], device=device)\n",
    "    dec_attn_mask = torch.ones_like(dec_input_ids, device=device)\n",
    "\n",
    "  # now do the decoder loop\n",
    "    for _ in range(32):\n",
    "        dec_output = model.decoder(\n",
    "            enc_output,\n",
    "            dec_input_ids,\n",
    "            enc_input['attention_mask'],\n",
    "            dec_attn_mask,\n",
    "        )\n",
    "\n",
    "        # choose the best value (or sample)\n",
    "        prediction_id = torch.argmax(dec_output[:, -1, :], axis=-1)\n",
    "\n",
    "        # append to decoder input\n",
    "        dec_input_ids = torch.hstack((dec_input_ids, prediction_id.view(1, 1)))\n",
    "\n",
    "        # recreate mask\n",
    "        dec_attn_mask = torch.ones_like(dec_input_ids)\n",
    "\n",
    "        # exit when reach </s>\n",
    "        if prediction_id == 0:\n",
    "            break\n",
    "  \n",
    "    translation = tokenizer.decode(dec_input_ids[0, 1:])\n",
    "    #print(translation)\n",
    "    return(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12261e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60deab8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "device='cuda'\n",
    "def objective(trial,epochs=3):\n",
    "    # Generate the model.\n",
    "    train_losses = np.zeros(epochs)\n",
    "    test_losses = np.zeros(epochs)\n",
    "    model = define_model(trial).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-3, log=True)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    for it in range(epochs):\n",
    "        t0 = datetime.now()\n",
    "        train_loss = []\n",
    "        for batch in train_loader:\n",
    "            # move data to GPU (enc_input, enc_mask, translation)\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            enc_input = batch['input_ids']\n",
    "            enc_mask = batch['attention_mask']\n",
    "            targets = batch['labels']\n",
    "\n",
    "            # shift targets forwards to get decoder_input\n",
    "            dec_input = targets.clone().detach()\n",
    "            dec_input = torch.roll(dec_input, shifts=1, dims=1)\n",
    "            dec_input[:, 0] = int(tokenizer.vocab_size)\n",
    "\n",
    "            # also convert all -100 to pad token id\n",
    "            dec_input = dec_input.masked_fill(\n",
    "              dec_input == -100, tokenizer.pad_token_id)\n",
    "\n",
    "            # make decoder input mask\n",
    "            dec_mask = torch.ones_like(dec_input)\n",
    "            dec_mask = dec_mask.masked_fill(dec_input == tokenizer.pad_token_id, 0)\n",
    "\n",
    "            # Forward pass\n",
    "            with torch.amp.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "                outputs = model(enc_input, dec_input, enc_mask, dec_mask)\n",
    "                loss = criterion(outputs.transpose(2, 1), targets)\n",
    "\n",
    "            # Backward and optimize\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        # Get train loss and test loss\n",
    "        train_loss = np.mean(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = []\n",
    "        for batch in valid_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            enc_input = batch['input_ids']\n",
    "            enc_mask = batch['attention_mask']\n",
    "            targets = batch['labels']\n",
    "\n",
    "            # shift targets forwards to get decoder_input\n",
    "            dec_input = targets.clone().detach()\n",
    "            dec_input = torch.roll(dec_input, shifts=1, dims=1)\n",
    "            dec_input[:, 0] = int(tokenizer.vocab_size)\n",
    "\n",
    "            # change -100s to regular padding\n",
    "            dec_input = dec_input.masked_fill(\n",
    "              dec_input == -100, tokenizer.pad_token_id)\n",
    "\n",
    "            # make decoder input mask\n",
    "            dec_mask = torch.ones_like(dec_input)\n",
    "            dec_mask = dec_mask.masked_fill(dec_input == tokenizer.pad_token_id, 0)\n",
    "\n",
    "            outputs = model(enc_input, dec_input, enc_mask, dec_mask)\n",
    "            #with torch.amp.autocast(device_type=‚Äúcuda‚Äù, dtype=torch.float16):\n",
    "            loss = criterion(outputs.transpose(2, 1), targets)\n",
    "            test_loss.append(loss.item())\n",
    "            \n",
    "            \n",
    "        translations=[]    \n",
    "        targets = []\n",
    "        bertscores = []\n",
    "        bleuscores = []\n",
    "        for  i in range(200):\n",
    "            translations.append(translate(split['test'][i][l1], model)[:-4])\n",
    "            targets.append(split['test'][i][l2])\n",
    "            score =bert_metric.compute(predictions=[translations[i]], references=[targets[i]], lang=\"ru\")['f1']\n",
    "            bertscores.append(score)\n",
    "            score =bleu_metric.compute(predictions=[translations[i]], references=[[targets[i]]])['score']\n",
    "            bleuscores.append(score)\n",
    "        print(f\"Mean BERT {np.mean(bertscores)}, Mean Bleu: {np.mean(bleuscores)}\" )\n",
    "        test_loss = np.mean(test_loss)\n",
    "\n",
    "        # Save losses\n",
    "        train_losses[it] = train_loss\n",
    "        test_losses[it] = test_loss\n",
    "\n",
    "        dt = datetime.now() - t0\n",
    "\n",
    "\n",
    "        print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, \\\n",
    "          Test Loss: {test_loss:.4f}, Duration: {dt}')\n",
    "    return(np.mean(bertscores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d61d51a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "162a3f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0107107c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-03-01 20:19:43,969]\u001B[0m A new study created in memory with name: no-name-268307ed-45a7-42d7-811c-7c4abee954ad\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33m[W 2023-03-01 20:20:32,293]\u001B[0m Trial 0 failed with parameters: {'n_heads': 7, 'n_layers': 3, 'lr': 0.00012237253778222962} because of the following error: KeyboardInterrupt().\u001B[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sutclw/anaconda3/envs/torch/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_8878/1066740464.py\", line 52, in objective\n",
      "    scaler.step(optimizer)\n",
      "  File \"/home/sutclw/.local/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py\", line 341, in step\n",
      "    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
      "  File \"/home/sutclw/.local/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py\", line 287, in _maybe_opt_step\n",
      "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
      "  File \"/home/sutclw/.local/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py\", line 287, in <genexpr>\n",
      "    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n",
      "KeyboardInterrupt\n",
      "\u001B[33m[W 2023-03-01 20:20:32,294]\u001B[0m Trial 0 failed with value None.\u001B[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjective\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m pruned_trials \u001B[38;5;241m=\u001B[39m study\u001B[38;5;241m.\u001B[39mget_trials(deepcopy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, states\u001B[38;5;241m=\u001B[39m[TrialState\u001B[38;5;241m.\u001B[39mPRUNED])\n\u001B[1;32m      5\u001B[0m complete_trials \u001B[38;5;241m=\u001B[39m study\u001B[38;5;241m.\u001B[39mget_trials(deepcopy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, states\u001B[38;5;241m=\u001B[39m[TrialState\u001B[38;5;241m.\u001B[39mCOMPLETE])\n",
      "File \u001B[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/optuna/study/study.py:425\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[1;32m    321\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimize\u001B[39m(\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    323\u001B[0m     func: ObjectiveFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    330\u001B[0m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    331\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    332\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[1;32m    333\u001B[0m \n\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    422\u001B[0m \u001B[38;5;124;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 425\u001B[0m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    426\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    427\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    428\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    429\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    430\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    431\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    432\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    433\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    434\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    435\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001B[0m, in \u001B[0;36m_optimize\u001B[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m---> 66\u001B[0m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     76\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     78\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     79\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[1;32m    160\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 163\u001B[0m     frozen_trial \u001B[38;5;241m=\u001B[39m \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    165\u001B[0m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[1;32m    167\u001B[0m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[1;32m    168\u001B[0m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[1;32m    169\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "File \u001B[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001B[0m, in \u001B[0;36m_run_trial\u001B[0;34m(study, func, catch)\u001B[0m\n\u001B[1;32m    244\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould not reach.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    247\u001B[0m     frozen_trial\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m==\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mFAIL\n\u001B[1;32m    248\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    249\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[1;32m    250\u001B[0m ):\n\u001B[0;32m--> 251\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "File \u001B[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001B[0m, in \u001B[0;36m_run_trial\u001B[0;34m(study, func, catch)\u001B[0m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial\u001B[38;5;241m.\u001B[39m_trial_id, study\u001B[38;5;241m.\u001B[39m_storage):\n\u001B[1;32m    199\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 200\u001B[0m         value_or_values \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    202\u001B[0m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[1;32m    203\u001B[0m         state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "Cell \u001B[0;32mIn[20], line 52\u001B[0m, in \u001B[0;36mobjective\u001B[0;34m(trial, epochs)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;66;03m# Backward and optimize\u001B[39;00m\n\u001B[1;32m     51\u001B[0m scaler\u001B[38;5;241m.\u001B[39mscale(loss)\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m---> 52\u001B[0m \u001B[43mscaler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     53\u001B[0m scaler\u001B[38;5;241m.\u001B[39mupdate()\n\u001B[1;32m     54\u001B[0m train_loss\u001B[38;5;241m.\u001B[39mappend(loss\u001B[38;5;241m.\u001B[39mitem())\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:341\u001B[0m, in \u001B[0;36mGradScaler.step\u001B[0;34m(self, optimizer, *args, **kwargs)\u001B[0m\n\u001B[1;32m    337\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39munscale_(optimizer)\n\u001B[1;32m    339\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(optimizer_state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf_per_device\u001B[39m\u001B[38;5;124m\"\u001B[39m]) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo inf checks were recorded for this optimizer.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 341\u001B[0m retval \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_opt_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    343\u001B[0m optimizer_state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstage\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m OptState\u001B[38;5;241m.\u001B[39mSTEPPED\n\u001B[1;32m    345\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m retval\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:287\u001B[0m, in \u001B[0;36mGradScaler._maybe_opt_step\u001B[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001B[0m\n\u001B[1;32m    285\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_maybe_opt_step\u001B[39m(\u001B[38;5;28mself\u001B[39m, optimizer, optimizer_state, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    286\u001B[0m     retval \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 287\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;43msum\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43moptimizer_state\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf_per_device\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    288\u001B[0m         retval \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39mstep(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    289\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m retval\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:287\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    285\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_maybe_opt_step\u001B[39m(\u001B[38;5;28mself\u001B[39m, optimizer, optimizer_state, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    286\u001B[0m     retval \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 287\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28msum\u001B[39m(\u001B[43mv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m optimizer_state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf_per_device\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues()):\n\u001B[1;32m    288\u001B[0m         retval \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39mstep(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    289\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m retval\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0f992a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  3\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  3\n",
      "Best trial:\n",
      "  Value:  0.7627686563134194\n",
      "  Params: \n",
      "    n_heads: 5\n",
      "    n_layers: 5\n",
      "    lr: 0.00021099837151687136\n"
     ]
    }
   ],
   "source": [
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4df646",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
